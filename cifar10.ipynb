{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bitaaaconda200f37d1b68c45ef8f1b952340469e3a",
   "display_name": "Python 3.6.10 64-bit ('AAA': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ten2PIL = torchvision.transforms.ToPILImage()\n",
    "PIL2Ten = torchvision.transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = torchvision.datasets.CIFAR10(root='data', train=True, transform=transform_train, download=True)\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(dataset, lengths=[int(0.9 * len(dataset)), len(dataset) - int(0.9*len(dataset))])\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='data', train=False, transform=transform_test, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "len(dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelClass(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(modelClass, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=5)\n",
    "        self.mp = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv1 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=64, kernel_size=2)\n",
    "        self.fc0 = nn.Linear(256, 64)\n",
    "        self.fc1 = nn.Linear(64, 16)\n",
    "        self.fc2 = nn.Linear(16, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.mp(F.relu(self.conv0(x)))\n",
    "        out = self.mp(F.relu(self.conv1(out)))\n",
    "        out = self.mp(F.relu(self.conv2(out)))\n",
    "        out = nn.Flatten()(out)\n",
    "        out = self.fc0(out)\n",
    "        out = self.fc1(out)\n",
    "        return self.fc2(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modelClass(num_classes=10).to(device) # torchvision.models.mobilenet_v2(num_classes=10).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfunc = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0 | Train loss: 2.3288 | Valid loss: 2.3301 | Valid Accu: 0.0960\n",
      "Epoch: 0 | Train loss: 2.2876 | Valid loss: 2.3258 | Valid Accu: 0.0992\n",
      "Epoch: 0 | Train loss: 2.3059 | Valid loss: 2.3221 | Valid Accu: 0.1126\n",
      "Epoch: 1 | Train loss: 2.2920 | Valid loss: 2.3193 | Valid Accu: 0.1180\n",
      "Epoch: 1 | Train loss: 2.3222 | Valid loss: 2.3156 | Valid Accu: 0.1126\n",
      "Epoch: 1 | Train loss: 2.2919 | Valid loss: 2.3100 | Valid Accu: 0.1206\n",
      "Epoch: 2 | Train loss: 2.3044 | Valid loss: 2.3022 | Valid Accu: 0.1214\n",
      "Epoch: 2 | Train loss: 2.2553 | Valid loss: 2.2816 | Valid Accu: 0.1362\n",
      "Epoch: 2 | Train loss: 2.1667 | Valid loss: 2.2417 | Valid Accu: 0.1658\n",
      "Epoch: 3 | Train loss: 2.1610 | Valid loss: 2.2094 | Valid Accu: 0.1900\n",
      "Epoch: 3 | Train loss: 2.0869 | Valid loss: 2.1687 | Valid Accu: 0.2030\n",
      "Epoch: 3 | Train loss: 2.0595 | Valid loss: 2.1274 | Valid Accu: 0.2128\n",
      "Epoch: 4 | Train loss: 2.1068 | Valid loss: 2.1025 | Valid Accu: 0.2224\n",
      "Epoch: 4 | Train loss: 1.9973 | Valid loss: 2.0844 | Valid Accu: 0.2228\n",
      "Epoch: 4 | Train loss: 2.0541 | Valid loss: 2.0733 | Valid Accu: 0.2300\n",
      "Epoch: 5 | Train loss: 2.0962 | Valid loss: 2.0606 | Valid Accu: 0.2362\n",
      "Epoch: 5 | Train loss: 1.9519 | Valid loss: 2.0400 | Valid Accu: 0.2530\n",
      "Epoch: 5 | Train loss: 1.8932 | Valid loss: 2.0277 | Valid Accu: 0.2468\n",
      "Epoch: 6 | Train loss: 2.0824 | Valid loss: 2.0063 | Valid Accu: 0.2634\n",
      "Epoch: 6 | Train loss: 2.0243 | Valid loss: 1.9882 | Valid Accu: 0.2618\n",
      "Epoch: 6 | Train loss: 2.1551 | Valid loss: 1.9763 | Valid Accu: 0.2658\n",
      "Epoch: 7 | Train loss: 1.7086 | Valid loss: 1.9533 | Valid Accu: 0.2820\n",
      "Epoch: 7 | Train loss: 1.7632 | Valid loss: 1.9313 | Valid Accu: 0.2824\n",
      "Epoch: 7 | Train loss: 2.0705 | Valid loss: 1.9212 | Valid Accu: 0.2878\n",
      "Epoch: 8 | Train loss: 1.9372 | Valid loss: 1.9124 | Valid Accu: 0.2924\n",
      "Epoch: 8 | Train loss: 1.9503 | Valid loss: 1.8858 | Valid Accu: 0.3032\n",
      "Epoch: 8 | Train loss: 1.8507 | Valid loss: 1.8792 | Valid Accu: 0.3086\n",
      "Epoch: 9 | Train loss: 1.7009 | Valid loss: 1.8877 | Valid Accu: 0.3002\n",
      "Epoch: 9 | Train loss: 2.0383 | Valid loss: 1.8453 | Valid Accu: 0.3138\n",
      "Epoch: 9 | Train loss: 1.8899 | Valid loss: 1.8311 | Valid Accu: 0.3200\n",
      "Epoch: 10 | Train loss: 1.6608 | Valid loss: 1.8441 | Valid Accu: 0.3206\n",
      "Epoch: 10 | Train loss: 1.7546 | Valid loss: 1.8192 | Valid Accu: 0.3246\n",
      "Epoch: 10 | Train loss: 2.0435 | Valid loss: 1.8122 | Valid Accu: 0.3352\n",
      "Epoch: 11 | Train loss: 1.8847 | Valid loss: 1.8120 | Valid Accu: 0.3350\n",
      "Epoch: 11 | Train loss: 1.9035 | Valid loss: 1.7912 | Valid Accu: 0.3384\n",
      "Epoch: 11 | Train loss: 1.9418 | Valid loss: 1.7815 | Valid Accu: 0.3512\n",
      "Epoch: 12 | Train loss: 1.7105 | Valid loss: 1.7812 | Valid Accu: 0.3360\n",
      "Epoch: 12 | Train loss: 1.7887 | Valid loss: 1.7696 | Valid Accu: 0.3464\n",
      "Epoch: 12 | Train loss: 1.8299 | Valid loss: 1.7521 | Valid Accu: 0.3612\n",
      "Epoch: 13 | Train loss: 1.8245 | Valid loss: 1.7482 | Valid Accu: 0.3520\n",
      "Epoch: 13 | Train loss: 1.7564 | Valid loss: 1.7332 | Valid Accu: 0.3562\n",
      "Epoch: 13 | Train loss: 1.8895 | Valid loss: 1.7264 | Valid Accu: 0.3674\n",
      "Epoch: 14 | Train loss: 1.8472 | Valid loss: 1.7195 | Valid Accu: 0.3688\n",
      "Epoch: 14 | Train loss: 1.6980 | Valid loss: 1.7112 | Valid Accu: 0.3724\n",
      "Epoch: 14 | Train loss: 1.6680 | Valid loss: 1.7063 | Valid Accu: 0.3666\n",
      "Epoch: 15 | Train loss: 1.6164 | Valid loss: 1.6951 | Valid Accu: 0.3780\n",
      "Epoch: 15 | Train loss: 1.5080 | Valid loss: 1.6862 | Valid Accu: 0.3880\n",
      "Epoch: 15 | Train loss: 1.4325 | Valid loss: 1.6723 | Valid Accu: 0.3858\n",
      "Epoch: 16 | Train loss: 1.3980 | Valid loss: 1.6558 | Valid Accu: 0.3918\n",
      "Epoch: 16 | Train loss: 1.7654 | Valid loss: 1.6582 | Valid Accu: 0.3928\n",
      "Epoch: 16 | Train loss: 1.7985 | Valid loss: 1.6610 | Valid Accu: 0.3942\n",
      "Epoch: 17 | Train loss: 1.6316 | Valid loss: 1.6624 | Valid Accu: 0.3980\n",
      "Epoch: 17 | Train loss: 1.6159 | Valid loss: 1.6612 | Valid Accu: 0.3970\n",
      "Epoch: 17 | Train loss: 1.7284 | Valid loss: 1.6487 | Valid Accu: 0.3972\n",
      "Epoch: 18 | Train loss: 2.1085 | Valid loss: 1.6178 | Valid Accu: 0.4096\n",
      "Epoch: 18 | Train loss: 1.7749 | Valid loss: 1.6355 | Valid Accu: 0.4014\n",
      "Epoch: 18 | Train loss: 1.5587 | Valid loss: 1.6065 | Valid Accu: 0.4168\n",
      "Epoch: 19 | Train loss: 1.3985 | Valid loss: 1.6169 | Valid Accu: 0.4102\n",
      "Epoch: 19 | Train loss: 1.6957 | Valid loss: 1.6033 | Valid Accu: 0.4258\n",
      "Epoch: 19 | Train loss: 1.3639 | Valid loss: 1.5956 | Valid Accu: 0.4212\n",
      "Epoch: 20 | Train loss: 1.5118 | Valid loss: 1.6051 | Valid Accu: 0.4096\n",
      "Epoch: 20 | Train loss: 1.7047 | Valid loss: 1.5735 | Valid Accu: 0.4230\n",
      "Epoch: 20 | Train loss: 1.7965 | Valid loss: 1.5866 | Valid Accu: 0.4264\n",
      "Epoch: 21 | Train loss: 1.3101 | Valid loss: 1.5965 | Valid Accu: 0.4182\n",
      "Epoch: 21 | Train loss: 1.5076 | Valid loss: 1.5579 | Valid Accu: 0.4334\n",
      "Epoch: 21 | Train loss: 1.7995 | Valid loss: 1.5613 | Valid Accu: 0.4324\n",
      "Epoch: 22 | Train loss: 1.6332 | Valid loss: 1.5852 | Valid Accu: 0.4222\n",
      "Epoch: 22 | Train loss: 1.1545 | Valid loss: 1.5606 | Valid Accu: 0.4376\n",
      "Epoch: 22 | Train loss: 1.3943 | Valid loss: 1.5456 | Valid Accu: 0.4444\n",
      "Epoch: 23 | Train loss: 1.7433 | Valid loss: 1.5450 | Valid Accu: 0.4486\n",
      "Epoch: 23 | Train loss: 1.8439 | Valid loss: 1.5611 | Valid Accu: 0.4402\n",
      "Epoch: 23 | Train loss: 1.4592 | Valid loss: 1.5472 | Valid Accu: 0.4382\n",
      "Epoch: 24 | Train loss: 1.5291 | Valid loss: 1.5276 | Valid Accu: 0.4530\n",
      "Epoch: 24 | Train loss: 1.6010 | Valid loss: 1.5315 | Valid Accu: 0.4348\n",
      "Epoch: 24 | Train loss: 1.3780 | Valid loss: 1.5480 | Valid Accu: 0.4428\n",
      "Epoch: 25 | Train loss: 1.5023 | Valid loss: 1.5291 | Valid Accu: 0.4472\n",
      "Epoch: 25 | Train loss: 1.4405 | Valid loss: 1.5324 | Valid Accu: 0.4458\n",
      "Epoch: 25 | Train loss: 1.5609 | Valid loss: 1.4996 | Valid Accu: 0.4526\n",
      "Epoch: 26 | Train loss: 1.3778 | Valid loss: 1.5805 | Valid Accu: 0.4304\n",
      "Epoch: 26 | Train loss: 1.2836 | Valid loss: 1.5217 | Valid Accu: 0.4546\n",
      "Epoch: 26 | Train loss: 1.4460 | Valid loss: 1.4992 | Valid Accu: 0.4582\n",
      "Epoch: 27 | Train loss: 1.3178 | Valid loss: 1.4943 | Valid Accu: 0.4612\n",
      "Epoch: 27 | Train loss: 1.8348 | Valid loss: 1.5045 | Valid Accu: 0.4554\n",
      "Epoch: 27 | Train loss: 1.7707 | Valid loss: 1.5124 | Valid Accu: 0.4650\n",
      "Epoch: 28 | Train loss: 1.2215 | Valid loss: 1.4865 | Valid Accu: 0.4664\n",
      "Epoch: 28 | Train loss: 1.5497 | Valid loss: 1.4755 | Valid Accu: 0.4766\n",
      "Epoch: 28 | Train loss: 1.3598 | Valid loss: 1.5222 | Valid Accu: 0.4572\n",
      "Epoch: 29 | Train loss: 1.4809 | Valid loss: 1.4913 | Valid Accu: 0.4688\n",
      "Epoch: 29 | Train loss: 1.5864 | Valid loss: 1.4802 | Valid Accu: 0.4730\n",
      "Epoch: 29 | Train loss: 1.3564 | Valid loss: 1.4666 | Valid Accu: 0.4738\n",
      "Epoch: 30 | Train loss: 2.0694 | Valid loss: 1.4613 | Valid Accu: 0.4744\n",
      "Epoch: 30 | Train loss: 1.6361 | Valid loss: 1.4641 | Valid Accu: 0.4758\n",
      "Epoch: 30 | Train loss: 1.4074 | Valid loss: 1.4569 | Valid Accu: 0.4802\n",
      "Epoch: 31 | Train loss: 1.3457 | Valid loss: 1.4751 | Valid Accu: 0.4688\n",
      "Epoch: 31 | Train loss: 1.4336 | Valid loss: 1.4632 | Valid Accu: 0.4780\n",
      "Epoch: 31 | Train loss: 1.1018 | Valid loss: 1.4527 | Valid Accu: 0.4840\n",
      "Epoch: 32 | Train loss: 1.4948 | Valid loss: 1.4452 | Valid Accu: 0.4814\n",
      "Epoch: 32 | Train loss: 1.2068 | Valid loss: 1.4327 | Valid Accu: 0.4962\n",
      "Epoch: 32 | Train loss: 1.3786 | Valid loss: 1.4340 | Valid Accu: 0.4860\n",
      "Epoch: 33 | Train loss: 1.2924 | Valid loss: 1.4568 | Valid Accu: 0.4714\n",
      "Epoch: 33 | Train loss: 1.2371 | Valid loss: 1.4267 | Valid Accu: 0.4920\n",
      "Epoch: 33 | Train loss: 1.4370 | Valid loss: 1.4276 | Valid Accu: 0.4914\n",
      "Epoch: 34 | Train loss: 1.4331 | Valid loss: 1.4236 | Valid Accu: 0.4926\n",
      "Epoch: 34 | Train loss: 1.5387 | Valid loss: 1.4182 | Valid Accu: 0.4934\n",
      "Epoch: 34 | Train loss: 1.2471 | Valid loss: 1.4209 | Valid Accu: 0.5018\n",
      "Epoch: 35 | Train loss: 1.8588 | Valid loss: 1.4527 | Valid Accu: 0.4774\n",
      "Epoch: 35 | Train loss: 1.4530 | Valid loss: 1.4102 | Valid Accu: 0.5022\n",
      "Epoch: 35 | Train loss: 1.6162 | Valid loss: 1.4459 | Valid Accu: 0.4862\n",
      "Epoch: 36 | Train loss: 1.3296 | Valid loss: 1.4163 | Valid Accu: 0.4918\n",
      "Epoch: 36 | Train loss: 1.3677 | Valid loss: 1.4305 | Valid Accu: 0.4968\n",
      "Epoch: 36 | Train loss: 1.3527 | Valid loss: 1.4084 | Valid Accu: 0.5046\n",
      "Epoch: 37 | Train loss: 1.2335 | Valid loss: 1.4276 | Valid Accu: 0.5046\n",
      "Epoch: 37 | Train loss: 1.2727 | Valid loss: 1.3851 | Valid Accu: 0.5076\n",
      "Epoch: 37 | Train loss: 1.2438 | Valid loss: 1.3763 | Valid Accu: 0.5148\n",
      "Epoch: 38 | Train loss: 1.5781 | Valid loss: 1.3890 | Valid Accu: 0.5080\n",
      "Epoch: 38 | Train loss: 1.3676 | Valid loss: 1.4144 | Valid Accu: 0.5018\n",
      "Epoch: 38 | Train loss: 1.1558 | Valid loss: 1.3934 | Valid Accu: 0.5000\n",
      "Epoch: 39 | Train loss: 1.4569 | Valid loss: 1.3900 | Valid Accu: 0.5098\n",
      "Epoch: 39 | Train loss: 1.2876 | Valid loss: 1.3812 | Valid Accu: 0.5108\n",
      "Epoch: 39 | Train loss: 1.2425 | Valid loss: 1.4000 | Valid Accu: 0.5072\n",
      "Epoch: 40 | Train loss: 1.5276 | Valid loss: 1.4050 | Valid Accu: 0.5012\n",
      "Epoch: 40 | Train loss: 1.2256 | Valid loss: 1.3931 | Valid Accu: 0.5144\n",
      "Epoch: 40 | Train loss: 1.3310 | Valid loss: 1.3791 | Valid Accu: 0.5178\n",
      "Epoch: 41 | Train loss: 1.6841 | Valid loss: 1.4031 | Valid Accu: 0.4974\n",
      "Epoch: 41 | Train loss: 1.2951 | Valid loss: 1.3634 | Valid Accu: 0.5190\n",
      "Epoch: 41 | Train loss: 0.9725 | Valid loss: 1.3627 | Valid Accu: 0.5218\n",
      "Epoch: 42 | Train loss: 1.8286 | Valid loss: 1.3889 | Valid Accu: 0.5122\n",
      "Epoch: 42 | Train loss: 1.5041 | Valid loss: 1.3822 | Valid Accu: 0.5134\n",
      "Epoch: 42 | Train loss: 1.2510 | Valid loss: 1.3743 | Valid Accu: 0.5178\n",
      "Epoch: 43 | Train loss: 1.4865 | Valid loss: 1.3563 | Valid Accu: 0.5218\n",
      "Epoch: 43 | Train loss: 1.4445 | Valid loss: 1.3649 | Valid Accu: 0.5234\n",
      "Epoch: 43 | Train loss: 1.3594 | Valid loss: 1.3509 | Valid Accu: 0.5320\n",
      "Epoch: 44 | Train loss: 1.1863 | Valid loss: 1.3557 | Valid Accu: 0.5242\n",
      "Epoch: 44 | Train loss: 1.0414 | Valid loss: 1.3404 | Valid Accu: 0.5272\n",
      "Epoch: 44 | Train loss: 1.1762 | Valid loss: 1.3721 | Valid Accu: 0.5242\n",
      "Epoch: 45 | Train loss: 1.4876 | Valid loss: 1.3720 | Valid Accu: 0.5150\n",
      "Epoch: 45 | Train loss: 1.4464 | Valid loss: 1.3431 | Valid Accu: 0.5212\n",
      "Epoch: 45 | Train loss: 1.7505 | Valid loss: 1.3300 | Valid Accu: 0.5402\n",
      "Epoch: 46 | Train loss: 1.1068 | Valid loss: 1.3574 | Valid Accu: 0.5186\n",
      "Epoch: 46 | Train loss: 1.1919 | Valid loss: 1.3472 | Valid Accu: 0.5312\n",
      "Epoch: 46 | Train loss: 1.1589 | Valid loss: 1.3401 | Valid Accu: 0.5340\n",
      "Epoch: 47 | Train loss: 1.0180 | Valid loss: 1.3413 | Valid Accu: 0.5286\n",
      "Epoch: 47 | Train loss: 1.1580 | Valid loss: 1.3351 | Valid Accu: 0.5356\n",
      "Epoch: 47 | Train loss: 1.2874 | Valid loss: 1.3242 | Valid Accu: 0.5332\n",
      "Epoch: 48 | Train loss: 1.0406 | Valid loss: 1.3369 | Valid Accu: 0.5376\n",
      "Epoch: 48 | Train loss: 1.3961 | Valid loss: 1.3091 | Valid Accu: 0.5472\n",
      "Epoch: 48 | Train loss: 1.3032 | Valid loss: 1.3246 | Valid Accu: 0.5338\n",
      "Epoch: 49 | Train loss: 1.3685 | Valid loss: 1.3025 | Valid Accu: 0.5424\n",
      "Epoch: 49 | Train loss: 1.3111 | Valid loss: 1.3023 | Valid Accu: 0.5486\n",
      "Epoch: 49 | Train loss: 1.2052 | Valid loss: 1.3152 | Valid Accu: 0.5416\n",
      "Epoch: 50 | Train loss: 1.7087 | Valid loss: 1.3133 | Valid Accu: 0.5386\n",
      "Epoch: 50 | Train loss: 1.2040 | Valid loss: 1.3188 | Valid Accu: 0.5428\n",
      "Epoch: 50 | Train loss: 0.8624 | Valid loss: 1.3087 | Valid Accu: 0.5406\n",
      "Epoch: 51 | Train loss: 1.1105 | Valid loss: 1.3355 | Valid Accu: 0.5416\n",
      "Epoch: 51 | Train loss: 1.6344 | Valid loss: 1.3177 | Valid Accu: 0.5350\n",
      "Epoch: 51 | Train loss: 1.3272 | Valid loss: 1.3086 | Valid Accu: 0.5388\n",
      "Epoch: 52 | Train loss: 1.3152 | Valid loss: 1.3007 | Valid Accu: 0.5526\n",
      "Epoch: 52 | Train loss: 1.1916 | Valid loss: 1.3103 | Valid Accu: 0.5342\n",
      "Epoch: 52 | Train loss: 1.4588 | Valid loss: 1.2930 | Valid Accu: 0.5470\n",
      "Epoch: 53 | Train loss: 0.7158 | Valid loss: 1.3476 | Valid Accu: 0.5318\n",
      "Epoch: 53 | Train loss: 1.2833 | Valid loss: 1.2913 | Valid Accu: 0.5406\n",
      "Epoch: 53 | Train loss: 1.3145 | Valid loss: 1.3018 | Valid Accu: 0.5498\n",
      "Epoch: 54 | Train loss: 1.2660 | Valid loss: 1.3120 | Valid Accu: 0.5394\n",
      "Epoch: 54 | Train loss: 1.0687 | Valid loss: 1.3224 | Valid Accu: 0.5388\n",
      "Epoch: 54 | Train loss: 1.1279 | Valid loss: 1.2856 | Valid Accu: 0.5542\n",
      "Epoch: 55 | Train loss: 1.4673 | Valid loss: 1.2766 | Valid Accu: 0.5574\n",
      "Epoch: 55 | Train loss: 1.1420 | Valid loss: 1.2767 | Valid Accu: 0.5490\n",
      "Epoch: 55 | Train loss: 1.4339 | Valid loss: 1.2900 | Valid Accu: 0.5476\n",
      "Epoch: 56 | Train loss: 1.2206 | Valid loss: 1.3172 | Valid Accu: 0.5438\n",
      "Epoch: 56 | Train loss: 1.2687 | Valid loss: 1.2744 | Valid Accu: 0.5556\n",
      "Epoch: 56 | Train loss: 1.2675 | Valid loss: 1.3058 | Valid Accu: 0.5440\n",
      "Epoch: 57 | Train loss: 1.4453 | Valid loss: 1.2544 | Valid Accu: 0.5606\n",
      "Epoch: 57 | Train loss: 1.3380 | Valid loss: 1.2779 | Valid Accu: 0.5528\n",
      "Epoch: 57 | Train loss: 1.5581 | Valid loss: 1.2634 | Valid Accu: 0.5594\n",
      "Epoch: 58 | Train loss: 1.3481 | Valid loss: 1.3121 | Valid Accu: 0.5422\n",
      "Epoch: 58 | Train loss: 1.1756 | Valid loss: 1.2736 | Valid Accu: 0.5568\n",
      "Epoch: 58 | Train loss: 1.0585 | Valid loss: 1.2726 | Valid Accu: 0.5622\n",
      "Epoch: 59 | Train loss: 1.2651 | Valid loss: 1.2568 | Valid Accu: 0.5618\n",
      "Epoch: 59 | Train loss: 1.0318 | Valid loss: 1.2635 | Valid Accu: 0.5580\n",
      "Epoch: 59 | Train loss: 1.1652 | Valid loss: 1.2758 | Valid Accu: 0.5608\n",
      "Epoch: 60 | Train loss: 1.4068 | Valid loss: 1.2747 | Valid Accu: 0.5566\n",
      "Epoch: 60 | Train loss: 1.3875 | Valid loss: 1.2521 | Valid Accu: 0.5588\n",
      "Epoch: 60 | Train loss: 1.2939 | Valid loss: 1.2607 | Valid Accu: 0.5598\n",
      "Epoch: 61 | Train loss: 1.2997 | Valid loss: 1.3016 | Valid Accu: 0.5470\n",
      "Epoch: 61 | Train loss: 1.5460 | Valid loss: 1.2787 | Valid Accu: 0.5536\n",
      "Epoch: 61 | Train loss: 1.2794 | Valid loss: 1.2504 | Valid Accu: 0.5686\n",
      "Epoch: 62 | Train loss: 1.0525 | Valid loss: 1.2849 | Valid Accu: 0.5498\n",
      "Epoch: 62 | Train loss: 1.0193 | Valid loss: 1.2676 | Valid Accu: 0.5612\n",
      "Epoch: 62 | Train loss: 1.0410 | Valid loss: 1.2655 | Valid Accu: 0.5570\n",
      "Epoch: 63 | Train loss: 1.1498 | Valid loss: 1.2836 | Valid Accu: 0.5618\n",
      "Epoch: 63 | Train loss: 1.1933 | Valid loss: 1.2618 | Valid Accu: 0.5722\n",
      "Epoch: 63 | Train loss: 1.4553 | Valid loss: 1.2579 | Valid Accu: 0.5608\n",
      "Epoch: 64 | Train loss: 1.2461 | Valid loss: 1.2426 | Valid Accu: 0.5690\n",
      "Epoch: 64 | Train loss: 1.0707 | Valid loss: 1.2538 | Valid Accu: 0.5644\n",
      "Epoch: 64 | Train loss: 0.8941 | Valid loss: 1.2360 | Valid Accu: 0.5738\n",
      "Epoch: 65 | Train loss: 1.3319 | Valid loss: 1.2592 | Valid Accu: 0.5578\n",
      "Epoch: 65 | Train loss: 1.1147 | Valid loss: 1.2293 | Valid Accu: 0.5784\n",
      "Epoch: 65 | Train loss: 1.6185 | Valid loss: 1.2680 | Valid Accu: 0.5588\n",
      "Epoch: 66 | Train loss: 1.2147 | Valid loss: 1.2639 | Valid Accu: 0.5602\n",
      "Epoch: 66 | Train loss: 1.0714 | Valid loss: 1.2443 | Valid Accu: 0.5636\n",
      "Epoch: 66 | Train loss: 1.4769 | Valid loss: 1.2563 | Valid Accu: 0.5638\n",
      "Epoch: 67 | Train loss: 1.3422 | Valid loss: 1.2504 | Valid Accu: 0.5730\n",
      "Epoch: 67 | Train loss: 1.2735 | Valid loss: 1.2615 | Valid Accu: 0.5612\n",
      "Epoch: 67 | Train loss: 1.2004 | Valid loss: 1.2387 | Valid Accu: 0.5684\n",
      "Epoch: 68 | Train loss: 1.4152 | Valid loss: 1.2228 | Valid Accu: 0.5808\n",
      "Epoch: 68 | Train loss: 1.1989 | Valid loss: 1.2324 | Valid Accu: 0.5798\n",
      "Epoch: 68 | Train loss: 1.9130 | Valid loss: 1.2349 | Valid Accu: 0.5790\n",
      "Epoch: 69 | Train loss: 0.9893 | Valid loss: 1.2341 | Valid Accu: 0.5734\n",
      "Epoch: 69 | Train loss: 1.2703 | Valid loss: 1.2297 | Valid Accu: 0.5766\n",
      "Epoch: 69 | Train loss: 1.0778 | Valid loss: 1.2214 | Valid Accu: 0.5844\n",
      "Epoch: 70 | Train loss: 1.4079 | Valid loss: 1.2273 | Valid Accu: 0.5766\n",
      "Epoch: 70 | Train loss: 0.8579 | Valid loss: 1.2302 | Valid Accu: 0.5762\n",
      "Epoch: 70 | Train loss: 0.8113 | Valid loss: 1.2316 | Valid Accu: 0.5766\n",
      "Epoch: 71 | Train loss: 1.2633 | Valid loss: 1.2352 | Valid Accu: 0.5718\n",
      "Epoch: 71 | Train loss: 0.9542 | Valid loss: 1.2287 | Valid Accu: 0.5756\n",
      "Epoch: 71 | Train loss: 1.4199 | Valid loss: 1.2259 | Valid Accu: 0.5754\n",
      "Epoch: 72 | Train loss: 0.9809 | Valid loss: 1.2180 | Valid Accu: 0.5822\n",
      "Epoch: 72 | Train loss: 0.8534 | Valid loss: 1.2129 | Valid Accu: 0.5818\n",
      "Epoch: 72 | Train loss: 1.0054 | Valid loss: 1.2256 | Valid Accu: 0.5736\n",
      "Epoch: 73 | Train loss: 1.1817 | Valid loss: 1.2395 | Valid Accu: 0.5792\n",
      "Epoch: 73 | Train loss: 1.1414 | Valid loss: 1.2068 | Valid Accu: 0.5850\n",
      "Epoch: 73 | Train loss: 1.0394 | Valid loss: 1.2265 | Valid Accu: 0.5834\n",
      "Epoch: 74 | Train loss: 1.1573 | Valid loss: 1.2518 | Valid Accu: 0.5706\n",
      "Epoch: 74 | Train loss: 1.3515 | Valid loss: 1.2088 | Valid Accu: 0.5906\n",
      "Epoch: 74 | Train loss: 1.0471 | Valid loss: 1.2012 | Valid Accu: 0.5858\n",
      "Epoch: 75 | Train loss: 1.5998 | Valid loss: 1.2616 | Valid Accu: 0.5644\n",
      "Epoch: 75 | Train loss: 0.8594 | Valid loss: 1.2133 | Valid Accu: 0.5828\n",
      "Epoch: 75 | Train loss: 1.6412 | Valid loss: 1.2017 | Valid Accu: 0.5794\n",
      "Epoch: 76 | Train loss: 1.2288 | Valid loss: 1.2188 | Valid Accu: 0.5730\n",
      "Epoch: 76 | Train loss: 0.7553 | Valid loss: 1.2117 | Valid Accu: 0.5854\n",
      "Epoch: 76 | Train loss: 1.2367 | Valid loss: 1.1900 | Valid Accu: 0.5852\n",
      "Epoch: 77 | Train loss: 1.3204 | Valid loss: 1.2118 | Valid Accu: 0.5886\n",
      "Epoch: 77 | Train loss: 1.1799 | Valid loss: 1.1966 | Valid Accu: 0.5862\n",
      "Epoch: 77 | Train loss: 1.3867 | Valid loss: 1.2080 | Valid Accu: 0.5846\n",
      "Epoch: 78 | Train loss: 0.9651 | Valid loss: 1.2253 | Valid Accu: 0.5842\n",
      "Epoch: 78 | Train loss: 1.3144 | Valid loss: 1.2036 | Valid Accu: 0.5914\n",
      "Epoch: 78 | Train loss: 0.9721 | Valid loss: 1.2067 | Valid Accu: 0.5874\n",
      "Epoch: 79 | Train loss: 1.1742 | Valid loss: 1.2611 | Valid Accu: 0.5726\n",
      "Epoch: 79 | Train loss: 1.0906 | Valid loss: 1.1910 | Valid Accu: 0.5924\n",
      "Epoch: 79 | Train loss: 1.7124 | Valid loss: 1.2136 | Valid Accu: 0.5840\n",
      "Epoch: 80 | Train loss: 1.0473 | Valid loss: 1.2232 | Valid Accu: 0.5778\n",
      "Epoch: 80 | Train loss: 0.8688 | Valid loss: 1.2036 | Valid Accu: 0.5802\n",
      "Epoch: 80 | Train loss: 1.0101 | Valid loss: 1.1876 | Valid Accu: 0.5968\n",
      "Epoch: 81 | Train loss: 1.5775 | Valid loss: 1.2387 | Valid Accu: 0.5672\n",
      "Epoch: 81 | Train loss: 1.3042 | Valid loss: 1.2107 | Valid Accu: 0.5898\n",
      "Epoch: 81 | Train loss: 1.4903 | Valid loss: 1.1777 | Valid Accu: 0.5844\n",
      "Epoch: 82 | Train loss: 1.0509 | Valid loss: 1.1921 | Valid Accu: 0.5882\n",
      "Epoch: 82 | Train loss: 1.5586 | Valid loss: 1.1932 | Valid Accu: 0.5878\n",
      "Epoch: 82 | Train loss: 1.0508 | Valid loss: 1.2217 | Valid Accu: 0.5884\n",
      "Epoch: 83 | Train loss: 1.3480 | Valid loss: 1.2091 | Valid Accu: 0.5808\n",
      "Epoch: 83 | Train loss: 0.7931 | Valid loss: 1.1888 | Valid Accu: 0.5904\n",
      "Epoch: 83 | Train loss: 1.3169 | Valid loss: 1.2104 | Valid Accu: 0.5824\n",
      "Epoch: 84 | Train loss: 1.3221 | Valid loss: 1.2618 | Valid Accu: 0.5644\n",
      "Epoch: 84 | Train loss: 0.9737 | Valid loss: 1.2125 | Valid Accu: 0.5858\n",
      "Epoch: 84 | Train loss: 1.1398 | Valid loss: 1.1988 | Valid Accu: 0.5852\n",
      "Epoch: 85 | Train loss: 0.9180 | Valid loss: 1.2573 | Valid Accu: 0.5690\n",
      "Epoch: 85 | Train loss: 0.9803 | Valid loss: 1.1886 | Valid Accu: 0.5976\n",
      "Epoch: 85 | Train loss: 1.0479 | Valid loss: 1.1826 | Valid Accu: 0.5964\n",
      "Epoch: 86 | Train loss: 1.2318 | Valid loss: 1.2558 | Valid Accu: 0.5616\n",
      "Epoch: 86 | Train loss: 1.4450 | Valid loss: 1.2005 | Valid Accu: 0.5948\n",
      "Epoch: 86 | Train loss: 1.4733 | Valid loss: 1.1722 | Valid Accu: 0.5860\n",
      "Epoch: 87 | Train loss: 1.2080 | Valid loss: 1.2468 | Valid Accu: 0.5690\n",
      "Epoch: 87 | Train loss: 0.9016 | Valid loss: 1.1864 | Valid Accu: 0.5948\n",
      "Epoch: 87 | Train loss: 1.1857 | Valid loss: 1.2163 | Valid Accu: 0.5812\n",
      "Epoch: 88 | Train loss: 0.8964 | Valid loss: 1.1733 | Valid Accu: 0.6002\n",
      "Epoch: 88 | Train loss: 1.2533 | Valid loss: 1.1708 | Valid Accu: 0.5984\n",
      "Epoch: 88 | Train loss: 1.3413 | Valid loss: 1.1791 | Valid Accu: 0.5932\n",
      "Epoch: 89 | Train loss: 0.9725 | Valid loss: 1.1768 | Valid Accu: 0.6046\n",
      "Epoch: 89 | Train loss: 1.1236 | Valid loss: 1.1714 | Valid Accu: 0.5908\n",
      "Epoch: 89 | Train loss: 1.1878 | Valid loss: 1.1702 | Valid Accu: 0.5966\n",
      "Epoch: 90 | Train loss: 1.2606 | Valid loss: 1.2281 | Valid Accu: 0.5768\n",
      "Epoch: 90 | Train loss: 1.3792 | Valid loss: 1.1980 | Valid Accu: 0.5912\n",
      "Epoch: 90 | Train loss: 0.9794 | Valid loss: 1.1673 | Valid Accu: 0.5942\n",
      "Epoch: 91 | Train loss: 0.8044 | Valid loss: 1.1968 | Valid Accu: 0.5846\n",
      "Epoch: 91 | Train loss: 0.9332 | Valid loss: 1.1742 | Valid Accu: 0.5998\n",
      "Epoch: 91 | Train loss: 0.9094 | Valid loss: 1.1948 | Valid Accu: 0.5964\n",
      "Epoch: 92 | Train loss: 1.1638 | Valid loss: 1.1945 | Valid Accu: 0.5940\n",
      "Epoch: 92 | Train loss: 1.1663 | Valid loss: 1.1583 | Valid Accu: 0.6026\n",
      "Epoch: 92 | Train loss: 1.2030 | Valid loss: 1.1597 | Valid Accu: 0.5970\n",
      "Epoch: 93 | Train loss: 0.8267 | Valid loss: 1.1837 | Valid Accu: 0.6048\n",
      "Epoch: 93 | Train loss: 1.3853 | Valid loss: 1.1666 | Valid Accu: 0.6036\n",
      "Epoch: 93 | Train loss: 0.8183 | Valid loss: 1.1743 | Valid Accu: 0.5970\n",
      "Epoch: 94 | Train loss: 1.0103 | Valid loss: 1.1908 | Valid Accu: 0.5946\n",
      "Epoch: 94 | Train loss: 1.0789 | Valid loss: 1.1685 | Valid Accu: 0.6016\n",
      "Epoch: 94 | Train loss: 1.4322 | Valid loss: 1.1768 | Valid Accu: 0.5950\n",
      "Epoch: 95 | Train loss: 1.3945 | Valid loss: 1.2062 | Valid Accu: 0.5928\n",
      "Epoch: 95 | Train loss: 1.0623 | Valid loss: 1.1886 | Valid Accu: 0.5914\n",
      "Epoch: 95 | Train loss: 1.1277 | Valid loss: 1.1640 | Valid Accu: 0.6072\n",
      "Epoch: 96 | Train loss: 1.3787 | Valid loss: 1.1975 | Valid Accu: 0.5890\n",
      "Epoch: 96 | Train loss: 0.9351 | Valid loss: 1.1743 | Valid Accu: 0.5950\n",
      "Epoch: 96 | Train loss: 1.3517 | Valid loss: 1.1623 | Valid Accu: 0.6026\n",
      "Epoch: 97 | Train loss: 1.2487 | Valid loss: 1.1956 | Valid Accu: 0.5884\n",
      "Epoch: 97 | Train loss: 1.0061 | Valid loss: 1.1731 | Valid Accu: 0.5996\n",
      "Epoch: 97 | Train loss: 1.0628 | Valid loss: 1.1607 | Valid Accu: 0.6030\n",
      "Epoch: 98 | Train loss: 1.3039 | Valid loss: 1.1791 | Valid Accu: 0.5936\n",
      "Epoch: 98 | Train loss: 0.9107 | Valid loss: 1.1427 | Valid Accu: 0.6092\n",
      "Epoch: 98 | Train loss: 1.4899 | Valid loss: 1.1589 | Valid Accu: 0.6102\n",
      "Epoch: 99 | Train loss: 1.3198 | Valid loss: 1.1962 | Valid Accu: 0.5862\n",
      "Epoch: 99 | Train loss: 1.1810 | Valid loss: 1.1642 | Valid Accu: 0.6094\n",
      "Epoch: 99 | Train loss: 1.1156 | Valid loss: 1.1646 | Valid Accu: 0.5968\n",
      "Epoch: 100 | Train loss: 0.7704 | Valid loss: 1.1596 | Valid Accu: 0.6022\n",
      "Epoch: 100 | Train loss: 1.0163 | Valid loss: 1.1406 | Valid Accu: 0.6128\n",
      "Epoch: 100 | Train loss: 1.1568 | Valid loss: 1.1680 | Valid Accu: 0.5938\n",
      "Epoch: 101 | Train loss: 1.0255 | Valid loss: 1.1692 | Valid Accu: 0.6050\n",
      "Epoch: 101 | Train loss: 1.4671 | Valid loss: 1.1617 | Valid Accu: 0.6040\n",
      "Epoch: 101 | Train loss: 1.5757 | Valid loss: 1.1476 | Valid Accu: 0.6036\n",
      "Epoch: 102 | Train loss: 1.1667 | Valid loss: 1.1584 | Valid Accu: 0.6036\n",
      "Epoch: 102 | Train loss: 1.0555 | Valid loss: 1.1578 | Valid Accu: 0.6062\n",
      "Epoch: 102 | Train loss: 0.8625 | Valid loss: 1.1335 | Valid Accu: 0.6158\n",
      "Epoch: 103 | Train loss: 1.1532 | Valid loss: 1.1631 | Valid Accu: 0.6088\n",
      "Epoch: 103 | Train loss: 0.9529 | Valid loss: 1.1882 | Valid Accu: 0.5956\n",
      "Epoch: 103 | Train loss: 1.1248 | Valid loss: 1.1485 | Valid Accu: 0.6084\n",
      "Epoch: 104 | Train loss: 1.1796 | Valid loss: 1.1490 | Valid Accu: 0.6116\n",
      "Epoch: 104 | Train loss: 1.3657 | Valid loss: 1.1456 | Valid Accu: 0.6086\n",
      "Epoch: 104 | Train loss: 1.3739 | Valid loss: 1.1443 | Valid Accu: 0.6064\n",
      "Epoch: 105 | Train loss: 1.1619 | Valid loss: 1.1536 | Valid Accu: 0.6036\n",
      "Epoch: 105 | Train loss: 1.1783 | Valid loss: 1.1582 | Valid Accu: 0.6036\n",
      "Epoch: 105 | Train loss: 0.8451 | Valid loss: 1.1552 | Valid Accu: 0.6052\n",
      "Epoch: 106 | Train loss: 1.3356 | Valid loss: 1.1592 | Valid Accu: 0.6050\n",
      "Epoch: 106 | Train loss: 0.8703 | Valid loss: 1.1397 | Valid Accu: 0.6078\n",
      "Epoch: 106 | Train loss: 1.0389 | Valid loss: 1.1258 | Valid Accu: 0.6140\n",
      "Epoch: 107 | Train loss: 0.8001 | Valid loss: 1.1589 | Valid Accu: 0.6062\n",
      "Epoch: 107 | Train loss: 1.3933 | Valid loss: 1.1413 | Valid Accu: 0.6104\n",
      "Epoch: 107 | Train loss: 0.9836 | Valid loss: 1.1696 | Valid Accu: 0.5986\n",
      "Epoch: 108 | Train loss: 1.0505 | Valid loss: 1.1634 | Valid Accu: 0.6010\n",
      "Epoch: 108 | Train loss: 1.4254 | Valid loss: 1.1380 | Valid Accu: 0.6164\n",
      "Epoch: 108 | Train loss: 1.1193 | Valid loss: 1.1264 | Valid Accu: 0.6178\n",
      "Epoch: 109 | Train loss: 1.1473 | Valid loss: 1.1591 | Valid Accu: 0.5998\n",
      "Epoch: 109 | Train loss: 0.9610 | Valid loss: 1.1403 | Valid Accu: 0.6126\n",
      "Epoch: 109 | Train loss: 1.1208 | Valid loss: 1.1373 | Valid Accu: 0.6080\n",
      "Epoch: 110 | Train loss: 1.4527 | Valid loss: 1.1302 | Valid Accu: 0.6166\n",
      "Epoch: 110 | Train loss: 0.8441 | Valid loss: 1.1560 | Valid Accu: 0.6002\n",
      "Epoch: 110 | Train loss: 1.1499 | Valid loss: 1.1633 | Valid Accu: 0.6078\n",
      "Epoch: 111 | Train loss: 0.8679 | Valid loss: 1.1735 | Valid Accu: 0.6002\n",
      "Epoch: 111 | Train loss: 1.0633 | Valid loss: 1.1447 | Valid Accu: 0.6112\n",
      "Epoch: 111 | Train loss: 1.0023 | Valid loss: 1.1500 | Valid Accu: 0.6086\n",
      "Epoch: 112 | Train loss: 1.4294 | Valid loss: 1.1584 | Valid Accu: 0.6066\n",
      "Epoch: 112 | Train loss: 1.1016 | Valid loss: 1.1108 | Valid Accu: 0.6198\n",
      "Epoch: 112 | Train loss: 1.0509 | Valid loss: 1.1303 | Valid Accu: 0.6202\n",
      "Epoch: 113 | Train loss: 1.3975 | Valid loss: 1.1456 | Valid Accu: 0.6126\n",
      "Epoch: 113 | Train loss: 1.1045 | Valid loss: 1.1270 | Valid Accu: 0.6088\n",
      "Epoch: 113 | Train loss: 0.8720 | Valid loss: 1.1229 | Valid Accu: 0.6116\n",
      "Epoch: 114 | Train loss: 0.9882 | Valid loss: 1.1348 | Valid Accu: 0.6140\n",
      "Epoch: 114 | Train loss: 1.2165 | Valid loss: 1.1330 | Valid Accu: 0.6108\n",
      "Epoch: 114 | Train loss: 1.1534 | Valid loss: 1.1237 | Valid Accu: 0.6076\n",
      "Epoch: 115 | Train loss: 0.9395 | Valid loss: 1.1607 | Valid Accu: 0.6040\n",
      "Epoch: 115 | Train loss: 1.2086 | Valid loss: 1.1182 | Valid Accu: 0.6178\n",
      "Epoch: 115 | Train loss: 1.3958 | Valid loss: 1.1122 | Valid Accu: 0.6190\n",
      "Epoch: 116 | Train loss: 0.9932 | Valid loss: 1.1699 | Valid Accu: 0.5978\n",
      "Epoch: 116 | Train loss: 0.9461 | Valid loss: 1.1380 | Valid Accu: 0.6076\n",
      "Epoch: 116 | Train loss: 0.7625 | Valid loss: 1.1043 | Valid Accu: 0.6176\n",
      "Epoch: 117 | Train loss: 0.9161 | Valid loss: 1.1312 | Valid Accu: 0.6188\n",
      "Epoch: 117 | Train loss: 1.2333 | Valid loss: 1.1332 | Valid Accu: 0.6114\n",
      "Epoch: 117 | Train loss: 1.0578 | Valid loss: 1.1231 | Valid Accu: 0.6160\n",
      "Epoch: 118 | Train loss: 1.1678 | Valid loss: 1.1548 | Valid Accu: 0.6044\n",
      "Epoch: 118 | Train loss: 0.7743 | Valid loss: 1.1236 | Valid Accu: 0.6188\n",
      "Epoch: 118 | Train loss: 1.0920 | Valid loss: 1.1435 | Valid Accu: 0.6052\n",
      "Epoch: 119 | Train loss: 1.3088 | Valid loss: 1.1190 | Valid Accu: 0.6184\n",
      "Epoch: 119 | Train loss: 1.3301 | Valid loss: 1.1045 | Valid Accu: 0.6194\n",
      "Epoch: 119 | Train loss: 0.8196 | Valid loss: 1.1393 | Valid Accu: 0.6108\n",
      "Epoch: 120 | Train loss: 1.2472 | Valid loss: 1.1342 | Valid Accu: 0.6180\n",
      "Epoch: 120 | Train loss: 1.0239 | Valid loss: 1.1182 | Valid Accu: 0.6130\n",
      "Epoch: 120 | Train loss: 1.0726 | Valid loss: 1.1141 | Valid Accu: 0.6152\n",
      "Epoch: 121 | Train loss: 1.4494 | Valid loss: 1.1214 | Valid Accu: 0.6170\n",
      "Epoch: 121 | Train loss: 1.2342 | Valid loss: 1.1124 | Valid Accu: 0.6180\n",
      "Epoch: 121 | Train loss: 0.7199 | Valid loss: 1.1207 | Valid Accu: 0.6134\n",
      "Epoch: 122 | Train loss: 1.3693 | Valid loss: 1.1187 | Valid Accu: 0.6136\n",
      "Epoch: 122 | Train loss: 0.9688 | Valid loss: 1.1177 | Valid Accu: 0.6222\n",
      "Epoch: 122 | Train loss: 0.8763 | Valid loss: 1.1162 | Valid Accu: 0.6258\n",
      "Epoch: 123 | Train loss: 1.0001 | Valid loss: 1.1713 | Valid Accu: 0.6016\n",
      "Epoch: 123 | Train loss: 1.2337 | Valid loss: 1.1280 | Valid Accu: 0.6208\n",
      "Epoch: 123 | Train loss: 1.0373 | Valid loss: 1.1145 | Valid Accu: 0.6264\n",
      "Epoch: 124 | Train loss: 0.7993 | Valid loss: 1.1334 | Valid Accu: 0.6092\n",
      "Epoch: 124 | Train loss: 1.2418 | Valid loss: 1.1151 | Valid Accu: 0.6104\n",
      "Epoch: 124 | Train loss: 1.3533 | Valid loss: 1.1245 | Valid Accu: 0.6120\n",
      "Epoch: 125 | Train loss: 0.9678 | Valid loss: 1.0979 | Valid Accu: 0.6204\n",
      "Epoch: 125 | Train loss: 0.6781 | Valid loss: 1.1396 | Valid Accu: 0.6124\n",
      "Epoch: 125 | Train loss: 1.5443 | Valid loss: 1.0934 | Valid Accu: 0.6334\n",
      "Epoch: 126 | Train loss: 1.1715 | Valid loss: 1.1005 | Valid Accu: 0.6272\n",
      "Epoch: 126 | Train loss: 0.9801 | Valid loss: 1.1006 | Valid Accu: 0.6168\n",
      "Epoch: 126 | Train loss: 0.8829 | Valid loss: 1.1290 | Valid Accu: 0.6248\n",
      "Epoch: 127 | Train loss: 0.8617 | Valid loss: 1.1268 | Valid Accu: 0.6256\n",
      "Epoch: 127 | Train loss: 0.9317 | Valid loss: 1.1408 | Valid Accu: 0.6094\n",
      "Epoch: 127 | Train loss: 1.2113 | Valid loss: 1.1183 | Valid Accu: 0.6190\n",
      "Epoch: 128 | Train loss: 0.8063 | Valid loss: 1.1046 | Valid Accu: 0.6304\n",
      "Epoch: 128 | Train loss: 0.9866 | Valid loss: 1.0949 | Valid Accu: 0.6214\n",
      "Epoch: 128 | Train loss: 0.7635 | Valid loss: 1.1290 | Valid Accu: 0.6186\n",
      "Epoch: 129 | Train loss: 1.3017 | Valid loss: 1.1311 | Valid Accu: 0.6096\n",
      "Epoch: 129 | Train loss: 1.0276 | Valid loss: 1.1008 | Valid Accu: 0.6198\n",
      "Epoch: 129 | Train loss: 1.2433 | Valid loss: 1.1121 | Valid Accu: 0.6212\n",
      "Epoch: 130 | Train loss: 1.1349 | Valid loss: 1.1280 | Valid Accu: 0.6160\n",
      "Epoch: 130 | Train loss: 0.9560 | Valid loss: 1.1171 | Valid Accu: 0.6160\n",
      "Epoch: 130 | Train loss: 0.9914 | Valid loss: 1.1067 | Valid Accu: 0.6288\n",
      "Epoch: 131 | Train loss: 0.9890 | Valid loss: 1.1263 | Valid Accu: 0.6152\n",
      "Epoch: 131 | Train loss: 0.8697 | Valid loss: 1.0960 | Valid Accu: 0.6298\n",
      "Epoch: 131 | Train loss: 1.1832 | Valid loss: 1.1300 | Valid Accu: 0.6150\n",
      "Epoch: 132 | Train loss: 1.0851 | Valid loss: 1.1195 | Valid Accu: 0.6150\n",
      "Epoch: 132 | Train loss: 0.8813 | Valid loss: 1.1414 | Valid Accu: 0.6074\n",
      "Epoch: 132 | Train loss: 1.7037 | Valid loss: 1.1068 | Valid Accu: 0.6230\n",
      "Epoch: 133 | Train loss: 0.8738 | Valid loss: 1.1295 | Valid Accu: 0.6148\n",
      "Epoch: 133 | Train loss: 1.3387 | Valid loss: 1.1657 | Valid Accu: 0.6076\n",
      "Epoch: 133 | Train loss: 1.0385 | Valid loss: 1.0939 | Valid Accu: 0.6284\n",
      "Epoch: 134 | Train loss: 1.3211 | Valid loss: 1.1133 | Valid Accu: 0.6280\n",
      "Epoch: 134 | Train loss: 1.0464 | Valid loss: 1.1202 | Valid Accu: 0.6258\n",
      "Epoch: 134 | Train loss: 0.7931 | Valid loss: 1.0861 | Valid Accu: 0.6270\n",
      "Epoch: 135 | Train loss: 0.8937 | Valid loss: 1.1156 | Valid Accu: 0.6146\n",
      "Epoch: 135 | Train loss: 0.7723 | Valid loss: 1.0989 | Valid Accu: 0.6226\n",
      "Epoch: 135 | Train loss: 1.3313 | Valid loss: 1.0997 | Valid Accu: 0.6176\n",
      "Epoch: 136 | Train loss: 0.8923 | Valid loss: 1.1015 | Valid Accu: 0.6184\n",
      "Epoch: 136 | Train loss: 1.0072 | Valid loss: 1.1180 | Valid Accu: 0.6112\n",
      "Epoch: 136 | Train loss: 1.1112 | Valid loss: 1.1182 | Valid Accu: 0.6224\n",
      "Epoch: 137 | Train loss: 1.1868 | Valid loss: 1.0730 | Valid Accu: 0.6282\n",
      "Epoch: 137 | Train loss: 1.1387 | Valid loss: 1.0983 | Valid Accu: 0.6236\n",
      "Epoch: 137 | Train loss: 0.6602 | Valid loss: 1.1138 | Valid Accu: 0.6178\n",
      "Epoch: 138 | Train loss: 0.9626 | Valid loss: 1.1087 | Valid Accu: 0.6160\n",
      "Epoch: 138 | Train loss: 1.2798 | Valid loss: 1.1025 | Valid Accu: 0.6334\n",
      "Epoch: 138 | Train loss: 0.7598 | Valid loss: 1.0958 | Valid Accu: 0.6214\n",
      "Epoch: 139 | Train loss: 0.8934 | Valid loss: 1.1117 | Valid Accu: 0.6142\n",
      "Epoch: 139 | Train loss: 0.9737 | Valid loss: 1.0983 | Valid Accu: 0.6194\n",
      "Epoch: 139 | Train loss: 0.7818 | Valid loss: 1.0815 | Valid Accu: 0.6358\n",
      "Epoch: 140 | Train loss: 0.8779 | Valid loss: 1.1153 | Valid Accu: 0.6272\n",
      "Epoch: 140 | Train loss: 1.0910 | Valid loss: 1.0847 | Valid Accu: 0.6326\n",
      "Epoch: 140 | Train loss: 0.9696 | Valid loss: 1.0933 | Valid Accu: 0.6234\n",
      "Epoch: 141 | Train loss: 0.6094 | Valid loss: 1.0966 | Valid Accu: 0.6256\n",
      "Epoch: 141 | Train loss: 1.1973 | Valid loss: 1.1093 | Valid Accu: 0.6160\n",
      "Epoch: 141 | Train loss: 1.2132 | Valid loss: 1.1261 | Valid Accu: 0.6188\n",
      "Epoch: 142 | Train loss: 0.8080 | Valid loss: 1.1163 | Valid Accu: 0.6166\n",
      "Epoch: 142 | Train loss: 0.9570 | Valid loss: 1.1146 | Valid Accu: 0.6214\n",
      "Epoch: 142 | Train loss: 0.9468 | Valid loss: 1.0846 | Valid Accu: 0.6364\n",
      "Epoch: 143 | Train loss: 1.1306 | Valid loss: 1.0792 | Valid Accu: 0.6310\n",
      "Epoch: 143 | Train loss: 0.9470 | Valid loss: 1.0935 | Valid Accu: 0.6242\n",
      "Epoch: 143 | Train loss: 1.2002 | Valid loss: 1.1349 | Valid Accu: 0.6098\n",
      "Epoch: 144 | Train loss: 0.7388 | Valid loss: 1.1239 | Valid Accu: 0.6180\n",
      "Epoch: 144 | Train loss: 0.9439 | Valid loss: 1.1113 | Valid Accu: 0.6238\n",
      "Epoch: 144 | Train loss: 1.5573 | Valid loss: 1.0864 | Valid Accu: 0.6352\n",
      "Epoch: 145 | Train loss: 1.5695 | Valid loss: 1.0959 | Valid Accu: 0.6220\n",
      "Epoch: 145 | Train loss: 1.2709 | Valid loss: 1.1028 | Valid Accu: 0.6294\n",
      "Epoch: 145 | Train loss: 1.2573 | Valid loss: 1.0754 | Valid Accu: 0.6342\n",
      "Epoch: 146 | Train loss: 1.2743 | Valid loss: 1.1192 | Valid Accu: 0.6162\n",
      "Epoch: 146 | Train loss: 1.0292 | Valid loss: 1.0805 | Valid Accu: 0.6308\n",
      "Epoch: 146 | Train loss: 1.0644 | Valid loss: 1.0910 | Valid Accu: 0.6372\n",
      "Epoch: 147 | Train loss: 0.7335 | Valid loss: 1.1128 | Valid Accu: 0.6244\n",
      "Epoch: 147 | Train loss: 1.0140 | Valid loss: 1.0938 | Valid Accu: 0.6286\n",
      "Epoch: 147 | Train loss: 0.8925 | Valid loss: 1.0892 | Valid Accu: 0.6340\n",
      "Epoch: 148 | Train loss: 0.8148 | Valid loss: 1.0760 | Valid Accu: 0.6374\n",
      "Epoch: 148 | Train loss: 0.9390 | Valid loss: 1.0767 | Valid Accu: 0.6334\n",
      "Epoch: 148 | Train loss: 0.7252 | Valid loss: 1.0930 | Valid Accu: 0.6216\n",
      "Epoch: 149 | Train loss: 1.0917 | Valid loss: 1.0945 | Valid Accu: 0.6316\n",
      "Epoch: 149 | Train loss: 1.0553 | Valid loss: 1.0864 | Valid Accu: 0.6272\n",
      "Epoch: 149 | Train loss: 1.0911 | Valid loss: 1.0896 | Valid Accu: 0.6214\n",
      "Epoch: 150 | Train loss: 0.8796 | Valid loss: 1.0621 | Valid Accu: 0.6392\n",
      "Epoch: 150 | Train loss: 1.1443 | Valid loss: 1.0696 | Valid Accu: 0.6386\n",
      "Epoch: 150 | Train loss: 0.9070 | Valid loss: 1.0716 | Valid Accu: 0.6306\n",
      "Epoch: 151 | Train loss: 1.1575 | Valid loss: 1.1003 | Valid Accu: 0.6224\n",
      "Epoch: 151 | Train loss: 1.1793 | Valid loss: 1.0904 | Valid Accu: 0.6200\n",
      "Epoch: 151 | Train loss: 1.1182 | Valid loss: 1.1018 | Valid Accu: 0.6264\n",
      "Epoch: 152 | Train loss: 1.5332 | Valid loss: 1.0982 | Valid Accu: 0.6310\n",
      "Epoch: 152 | Train loss: 0.8827 | Valid loss: 1.0811 | Valid Accu: 0.6318\n",
      "Epoch: 152 | Train loss: 1.0540 | Valid loss: 1.1001 | Valid Accu: 0.6266\n",
      "Epoch: 153 | Train loss: 1.5668 | Valid loss: 1.0908 | Valid Accu: 0.6342\n",
      "Epoch: 153 | Train loss: 1.0712 | Valid loss: 1.0735 | Valid Accu: 0.6314\n",
      "Epoch: 153 | Train loss: 0.8544 | Valid loss: 1.0769 | Valid Accu: 0.6382\n",
      "Epoch: 154 | Train loss: 0.9656 | Valid loss: 1.1189 | Valid Accu: 0.6188\n",
      "Epoch: 154 | Train loss: 1.0611 | Valid loss: 1.0883 | Valid Accu: 0.6288\n",
      "Epoch: 154 | Train loss: 1.0560 | Valid loss: 1.0939 | Valid Accu: 0.6334\n",
      "Epoch: 155 | Train loss: 1.3218 | Valid loss: 1.1045 | Valid Accu: 0.6168\n",
      "Epoch: 155 | Train loss: 0.7361 | Valid loss: 1.1080 | Valid Accu: 0.6286\n",
      "Epoch: 155 | Train loss: 0.9869 | Valid loss: 1.0765 | Valid Accu: 0.6344\n",
      "Epoch: 156 | Train loss: 1.0251 | Valid loss: 1.0976 | Valid Accu: 0.6226\n",
      "Epoch: 156 | Train loss: 0.8533 | Valid loss: 1.0889 | Valid Accu: 0.6256\n",
      "Epoch: 156 | Train loss: 0.7981 | Valid loss: 1.0764 | Valid Accu: 0.6280\n",
      "Epoch: 157 | Train loss: 1.0375 | Valid loss: 1.0687 | Valid Accu: 0.6328\n",
      "Epoch: 157 | Train loss: 1.0814 | Valid loss: 1.0935 | Valid Accu: 0.6272\n",
      "Epoch: 157 | Train loss: 0.8636 | Valid loss: 1.0612 | Valid Accu: 0.6372\n",
      "Epoch: 158 | Train loss: 1.0378 | Valid loss: 1.0710 | Valid Accu: 0.6376\n",
      "Epoch: 158 | Train loss: 0.8721 | Valid loss: 1.0711 | Valid Accu: 0.6412\n",
      "Epoch: 158 | Train loss: 1.1087 | Valid loss: 1.0549 | Valid Accu: 0.6438\n",
      "Epoch: 159 | Train loss: 0.9431 | Valid loss: 1.1071 | Valid Accu: 0.6128\n",
      "Epoch: 159 | Train loss: 1.1379 | Valid loss: 1.0706 | Valid Accu: 0.6400\n",
      "Epoch: 159 | Train loss: 1.3698 | Valid loss: 1.0720 | Valid Accu: 0.6338\n",
      "Epoch: 160 | Train loss: 0.8372 | Valid loss: 1.0631 | Valid Accu: 0.6338\n",
      "Epoch: 160 | Train loss: 0.7965 | Valid loss: 1.0621 | Valid Accu: 0.6434\n",
      "Epoch: 160 | Train loss: 0.8551 | Valid loss: 1.0523 | Valid Accu: 0.6374\n",
      "Epoch: 161 | Train loss: 0.8935 | Valid loss: 1.0846 | Valid Accu: 0.6306\n",
      "Epoch: 161 | Train loss: 0.8164 | Valid loss: 1.0644 | Valid Accu: 0.6348\n",
      "Epoch: 161 | Train loss: 0.9616 | Valid loss: 1.0584 | Valid Accu: 0.6448\n",
      "Epoch: 162 | Train loss: 1.0657 | Valid loss: 1.0822 | Valid Accu: 0.6402\n",
      "Epoch: 162 | Train loss: 0.9928 | Valid loss: 1.0762 | Valid Accu: 0.6314\n",
      "Epoch: 162 | Train loss: 0.9669 | Valid loss: 1.0649 | Valid Accu: 0.6346\n",
      "Epoch: 163 | Train loss: 0.6158 | Valid loss: 1.0842 | Valid Accu: 0.6396\n",
      "Epoch: 163 | Train loss: 0.9867 | Valid loss: 1.0911 | Valid Accu: 0.6248\n",
      "Epoch: 163 | Train loss: 0.7251 | Valid loss: 1.0795 | Valid Accu: 0.6356\n",
      "Epoch: 164 | Train loss: 0.9963 | Valid loss: 1.0627 | Valid Accu: 0.6338\n",
      "Epoch: 164 | Train loss: 1.1579 | Valid loss: 1.0784 | Valid Accu: 0.6384\n",
      "Epoch: 164 | Train loss: 1.2092 | Valid loss: 1.0861 | Valid Accu: 0.6320\n",
      "Epoch: 165 | Train loss: 1.2156 | Valid loss: 1.0631 | Valid Accu: 0.6344\n",
      "Epoch: 165 | Train loss: 0.8640 | Valid loss: 1.0565 | Valid Accu: 0.6376\n",
      "Epoch: 165 | Train loss: 1.2274 | Valid loss: 1.0727 | Valid Accu: 0.6310\n",
      "Epoch: 166 | Train loss: 1.0304 | Valid loss: 1.0811 | Valid Accu: 0.6334\n",
      "Epoch: 166 | Train loss: 0.8756 | Valid loss: 1.0770 | Valid Accu: 0.6310\n",
      "Epoch: 166 | Train loss: 1.0335 | Valid loss: 1.0650 | Valid Accu: 0.6444\n",
      "Epoch: 167 | Train loss: 1.0069 | Valid loss: 1.0729 | Valid Accu: 0.6322\n",
      "Epoch: 167 | Train loss: 1.3141 | Valid loss: 1.0641 | Valid Accu: 0.6394\n",
      "Epoch: 167 | Train loss: 0.9970 | Valid loss: 1.0606 | Valid Accu: 0.6344\n",
      "Epoch: 168 | Train loss: 1.1676 | Valid loss: 1.0842 | Valid Accu: 0.6300\n",
      "Epoch: 168 | Train loss: 1.1743 | Valid loss: 1.0729 | Valid Accu: 0.6254\n",
      "Epoch: 168 | Train loss: 0.8099 | Valid loss: 1.0527 | Valid Accu: 0.6478\n",
      "Epoch: 169 | Train loss: 0.9179 | Valid loss: 1.1040 | Valid Accu: 0.6210\n",
      "Epoch: 169 | Train loss: 0.7525 | Valid loss: 1.0641 | Valid Accu: 0.6412\n",
      "Epoch: 169 | Train loss: 1.0042 | Valid loss: 1.0569 | Valid Accu: 0.6396\n",
      "Epoch: 170 | Train loss: 1.1027 | Valid loss: 1.0822 | Valid Accu: 0.6292\n",
      "Epoch: 170 | Train loss: 0.9670 | Valid loss: 1.0720 | Valid Accu: 0.6306\n",
      "Epoch: 170 | Train loss: 1.1150 | Valid loss: 1.0783 | Valid Accu: 0.6256\n",
      "Epoch: 171 | Train loss: 1.1599 | Valid loss: 1.0825 | Valid Accu: 0.6264\n",
      "Epoch: 171 | Train loss: 1.0157 | Valid loss: 1.0869 | Valid Accu: 0.6258\n",
      "Epoch: 171 | Train loss: 0.9960 | Valid loss: 1.0594 | Valid Accu: 0.6418\n",
      "Epoch: 172 | Train loss: 1.5104 | Valid loss: 1.0772 | Valid Accu: 0.6398\n",
      "Epoch: 172 | Train loss: 0.9254 | Valid loss: 1.0742 | Valid Accu: 0.6362\n",
      "Epoch: 172 | Train loss: 0.9231 | Valid loss: 1.0640 | Valid Accu: 0.6338\n",
      "Epoch: 173 | Train loss: 1.1093 | Valid loss: 1.0586 | Valid Accu: 0.6446\n",
      "Epoch: 173 | Train loss: 0.7708 | Valid loss: 1.0774 | Valid Accu: 0.6364\n",
      "Epoch: 173 | Train loss: 1.2194 | Valid loss: 1.0734 | Valid Accu: 0.6320\n",
      "Epoch: 174 | Train loss: 0.9011 | Valid loss: 1.0579 | Valid Accu: 0.6358\n",
      "Epoch: 174 | Train loss: 0.9223 | Valid loss: 1.0563 | Valid Accu: 0.6350\n",
      "Epoch: 174 | Train loss: 0.9448 | Valid loss: 1.0715 | Valid Accu: 0.6358\n",
      "Epoch: 175 | Train loss: 0.8085 | Valid loss: 1.0529 | Valid Accu: 0.6364\n",
      "Epoch: 175 | Train loss: 1.1852 | Valid loss: 1.0660 | Valid Accu: 0.6368\n",
      "Epoch: 175 | Train loss: 1.3994 | Valid loss: 1.0669 | Valid Accu: 0.6362\n",
      "Epoch: 176 | Train loss: 1.2216 | Valid loss: 1.0550 | Valid Accu: 0.6386\n",
      "Epoch: 176 | Train loss: 0.7224 | Valid loss: 1.0632 | Valid Accu: 0.6384\n",
      "Epoch: 176 | Train loss: 0.9473 | Valid loss: 1.0701 | Valid Accu: 0.6346\n",
      "Epoch: 177 | Train loss: 1.0664 | Valid loss: 1.0424 | Valid Accu: 0.6428\n",
      "Epoch: 177 | Train loss: 1.0739 | Valid loss: 1.0706 | Valid Accu: 0.6356\n",
      "Epoch: 177 | Train loss: 0.7315 | Valid loss: 1.0642 | Valid Accu: 0.6386\n",
      "Epoch: 178 | Train loss: 0.7762 | Valid loss: 1.0558 | Valid Accu: 0.6404\n",
      "Epoch: 178 | Train loss: 1.0847 | Valid loss: 1.0574 | Valid Accu: 0.6424\n",
      "Epoch: 178 | Train loss: 1.0596 | Valid loss: 1.0673 | Valid Accu: 0.6370\n",
      "Epoch: 179 | Train loss: 0.9002 | Valid loss: 1.0895 | Valid Accu: 0.6300\n",
      "Epoch: 179 | Train loss: 1.0660 | Valid loss: 1.0511 | Valid Accu: 0.6430\n",
      "Epoch: 179 | Train loss: 1.2716 | Valid loss: 1.0415 | Valid Accu: 0.6498\n",
      "Epoch: 180 | Train loss: 0.9285 | Valid loss: 1.0587 | Valid Accu: 0.6378\n",
      "Epoch: 180 | Train loss: 1.4857 | Valid loss: 1.0687 | Valid Accu: 0.6300\n",
      "Epoch: 180 | Train loss: 0.7930 | Valid loss: 1.0486 | Valid Accu: 0.6352\n",
      "Epoch: 181 | Train loss: 1.1745 | Valid loss: 1.1055 | Valid Accu: 0.6224\n",
      "Epoch: 181 | Train loss: 1.1538 | Valid loss: 1.0446 | Valid Accu: 0.6372\n",
      "Epoch: 181 | Train loss: 1.2091 | Valid loss: 1.0328 | Valid Accu: 0.6412\n",
      "Epoch: 182 | Train loss: 1.3738 | Valid loss: 1.0780 | Valid Accu: 0.6336\n",
      "Epoch: 182 | Train loss: 0.9609 | Valid loss: 1.0388 | Valid Accu: 0.6470\n",
      "Epoch: 182 | Train loss: 1.0335 | Valid loss: 1.0658 | Valid Accu: 0.6354\n",
      "Epoch: 183 | Train loss: 0.8434 | Valid loss: 1.0436 | Valid Accu: 0.6404\n",
      "Epoch: 183 | Train loss: 0.7010 | Valid loss: 1.0531 | Valid Accu: 0.6436\n",
      "Epoch: 183 | Train loss: 1.0520 | Valid loss: 1.0505 | Valid Accu: 0.6390\n",
      "Epoch: 184 | Train loss: 1.2591 | Valid loss: 1.0773 | Valid Accu: 0.6346\n",
      "Epoch: 184 | Train loss: 1.0037 | Valid loss: 1.0442 | Valid Accu: 0.6494\n",
      "Epoch: 184 | Train loss: 1.0723 | Valid loss: 1.0488 | Valid Accu: 0.6354\n",
      "Epoch: 185 | Train loss: 0.9588 | Valid loss: 1.0825 | Valid Accu: 0.6318\n",
      "Epoch: 185 | Train loss: 1.1342 | Valid loss: 1.0568 | Valid Accu: 0.6402\n",
      "Epoch: 185 | Train loss: 1.3891 | Valid loss: 1.0445 | Valid Accu: 0.6410\n",
      "Epoch: 186 | Train loss: 0.9014 | Valid loss: 1.0660 | Valid Accu: 0.6272\n",
      "Epoch: 186 | Train loss: 0.8672 | Valid loss: 1.0722 | Valid Accu: 0.6404\n",
      "Epoch: 186 | Train loss: 1.0383 | Valid loss: 1.0520 | Valid Accu: 0.6340\n",
      "Epoch: 187 | Train loss: 0.9283 | Valid loss: 1.0622 | Valid Accu: 0.6478\n",
      "Epoch: 187 | Train loss: 0.5764 | Valid loss: 1.0384 | Valid Accu: 0.6520\n",
      "Epoch: 187 | Train loss: 0.9522 | Valid loss: 1.0162 | Valid Accu: 0.6472\n",
      "Epoch: 188 | Train loss: 0.7138 | Valid loss: 1.0695 | Valid Accu: 0.6298\n",
      "Epoch: 188 | Train loss: 1.0541 | Valid loss: 1.0470 | Valid Accu: 0.6494\n",
      "Epoch: 188 | Train loss: 1.1963 | Valid loss: 1.0633 | Valid Accu: 0.6320\n",
      "Epoch: 189 | Train loss: 0.8509 | Valid loss: 1.0482 | Valid Accu: 0.6462\n",
      "Epoch: 189 | Train loss: 1.0699 | Valid loss: 1.0371 | Valid Accu: 0.6432\n",
      "Epoch: 189 | Train loss: 1.4309 | Valid loss: 1.0400 | Valid Accu: 0.6442\n",
      "Epoch: 190 | Train loss: 0.7480 | Valid loss: 1.0688 | Valid Accu: 0.6352\n",
      "Epoch: 190 | Train loss: 0.9120 | Valid loss: 1.0416 | Valid Accu: 0.6360\n",
      "Epoch: 190 | Train loss: 0.9772 | Valid loss: 1.0882 | Valid Accu: 0.6318\n",
      "Epoch: 191 | Train loss: 0.8909 | Valid loss: 1.0483 | Valid Accu: 0.6432\n",
      "Epoch: 191 | Train loss: 0.9948 | Valid loss: 1.0414 | Valid Accu: 0.6440\n",
      "Epoch: 191 | Train loss: 0.8666 | Valid loss: 1.0666 | Valid Accu: 0.6322\n",
      "Epoch: 192 | Train loss: 1.2474 | Valid loss: 1.0506 | Valid Accu: 0.6428\n",
      "Epoch: 192 | Train loss: 1.3258 | Valid loss: 1.0450 | Valid Accu: 0.6386\n",
      "Epoch: 192 | Train loss: 0.9827 | Valid loss: 1.0369 | Valid Accu: 0.6466\n",
      "Epoch: 193 | Train loss: 0.6977 | Valid loss: 1.0437 | Valid Accu: 0.6452\n",
      "Epoch: 193 | Train loss: 0.8109 | Valid loss: 1.0415 | Valid Accu: 0.6392\n",
      "Epoch: 193 | Train loss: 1.0426 | Valid loss: 1.0674 | Valid Accu: 0.6326\n",
      "Epoch: 194 | Train loss: 0.9790 | Valid loss: 1.0420 | Valid Accu: 0.6390\n",
      "Epoch: 194 | Train loss: 0.9879 | Valid loss: 1.0637 | Valid Accu: 0.6402\n",
      "Epoch: 194 | Train loss: 0.8616 | Valid loss: 1.0571 | Valid Accu: 0.6378\n",
      "Epoch: 195 | Train loss: 0.8369 | Valid loss: 1.0450 | Valid Accu: 0.6406\n",
      "Epoch: 195 | Train loss: 0.7352 | Valid loss: 1.0342 | Valid Accu: 0.6454\n",
      "Epoch: 195 | Train loss: 0.8569 | Valid loss: 1.0450 | Valid Accu: 0.6444\n",
      "Epoch: 196 | Train loss: 1.1532 | Valid loss: 1.0627 | Valid Accu: 0.6420\n",
      "Epoch: 196 | Train loss: 1.3431 | Valid loss: 1.0318 | Valid Accu: 0.6438\n",
      "Epoch: 196 | Train loss: 1.2099 | Valid loss: 1.0668 | Valid Accu: 0.6312\n",
      "Epoch: 197 | Train loss: 1.3148 | Valid loss: 1.1116 | Valid Accu: 0.6170\n",
      "Epoch: 197 | Train loss: 0.7562 | Valid loss: 1.0473 | Valid Accu: 0.6484\n",
      "Epoch: 197 | Train loss: 1.3395 | Valid loss: 1.0473 | Valid Accu: 0.6402\n",
      "Epoch: 198 | Train loss: 0.8586 | Valid loss: 1.0375 | Valid Accu: 0.6426\n",
      "Epoch: 198 | Train loss: 0.7995 | Valid loss: 1.0341 | Valid Accu: 0.6534\n",
      "Epoch: 198 | Train loss: 0.8773 | Valid loss: 1.0505 | Valid Accu: 0.6436\n",
      "Epoch: 199 | Train loss: 0.9576 | Valid loss: 1.0398 | Valid Accu: 0.6480\n",
      "Epoch: 199 | Train loss: 0.9126 | Valid loss: 1.0250 | Valid Accu: 0.6530\n",
      "Epoch: 199 | Train loss: 0.8550 | Valid loss: 1.0552 | Valid Accu: 0.6424\n",
      "Epoch: 200 | Train loss: 1.3498 | Valid loss: 1.0314 | Valid Accu: 0.6508\n",
      "Epoch: 200 | Train loss: 1.4280 | Valid loss: 1.0488 | Valid Accu: 0.6412\n",
      "Epoch: 200 | Train loss: 0.8555 | Valid loss: 1.0441 | Valid Accu: 0.6434\n",
      "Epoch: 201 | Train loss: 1.1406 | Valid loss: 1.0531 | Valid Accu: 0.6492\n",
      "Epoch: 201 | Train loss: 0.7742 | Valid loss: 1.0354 | Valid Accu: 0.6504\n",
      "Epoch: 201 | Train loss: 0.8218 | Valid loss: 1.0414 | Valid Accu: 0.6448\n",
      "Epoch: 202 | Train loss: 0.9836 | Valid loss: 1.0632 | Valid Accu: 0.6378\n",
      "Epoch: 202 | Train loss: 1.1721 | Valid loss: 1.0658 | Valid Accu: 0.6326\n",
      "Epoch: 202 | Train loss: 0.9777 | Valid loss: 1.0214 | Valid Accu: 0.6506\n",
      "Epoch: 203 | Train loss: 1.1079 | Valid loss: 1.0964 | Valid Accu: 0.6272\n",
      "Epoch: 203 | Train loss: 0.9416 | Valid loss: 1.0587 | Valid Accu: 0.6414\n",
      "Epoch: 203 | Train loss: 1.0861 | Valid loss: 1.0188 | Valid Accu: 0.6500\n",
      "Epoch: 204 | Train loss: 1.3523 | Valid loss: 1.0499 | Valid Accu: 0.6404\n",
      "Epoch: 204 | Train loss: 0.9017 | Valid loss: 1.0516 | Valid Accu: 0.6386\n",
      "Epoch: 204 | Train loss: 0.5359 | Valid loss: 1.0314 | Valid Accu: 0.6416\n",
      "Epoch: 205 | Train loss: 1.2128 | Valid loss: 1.0773 | Valid Accu: 0.6294\n",
      "Epoch: 205 | Train loss: 1.0838 | Valid loss: 1.0365 | Valid Accu: 0.6456\n",
      "Epoch: 205 | Train loss: 0.9728 | Valid loss: 1.0571 | Valid Accu: 0.6496\n",
      "Epoch: 206 | Train loss: 0.9682 | Valid loss: 1.0554 | Valid Accu: 0.6416\n",
      "Epoch: 206 | Train loss: 0.9143 | Valid loss: 1.0362 | Valid Accu: 0.6500\n",
      "Epoch: 206 | Train loss: 1.1819 | Valid loss: 1.0584 | Valid Accu: 0.6428\n",
      "Epoch: 207 | Train loss: 1.1785 | Valid loss: 1.0431 | Valid Accu: 0.6502\n",
      "Epoch: 207 | Train loss: 0.7103 | Valid loss: 1.0057 | Valid Accu: 0.6616\n",
      "Epoch: 207 | Train loss: 0.9849 | Valid loss: 1.0445 | Valid Accu: 0.6468\n",
      "Epoch: 208 | Train loss: 1.0199 | Valid loss: 1.0494 | Valid Accu: 0.6454\n",
      "Epoch: 208 | Train loss: 0.6693 | Valid loss: 1.0499 | Valid Accu: 0.6432\n",
      "Epoch: 208 | Train loss: 1.0452 | Valid loss: 1.0441 | Valid Accu: 0.6428\n",
      "Epoch: 209 | Train loss: 1.1714 | Valid loss: 1.0523 | Valid Accu: 0.6414\n",
      "Epoch: 209 | Train loss: 0.5914 | Valid loss: 1.0265 | Valid Accu: 0.6554\n",
      "Epoch: 209 | Train loss: 1.2458 | Valid loss: 1.0143 | Valid Accu: 0.6506\n",
      "Epoch: 210 | Train loss: 1.2352 | Valid loss: 1.0746 | Valid Accu: 0.6320\n",
      "Epoch: 210 | Train loss: 0.8457 | Valid loss: 1.0175 | Valid Accu: 0.6524\n",
      "Epoch: 210 | Train loss: 0.7772 | Valid loss: 1.0214 | Valid Accu: 0.6566\n",
      "Epoch: 211 | Train loss: 0.9298 | Valid loss: 1.0400 | Valid Accu: 0.6506\n",
      "Epoch: 211 | Train loss: 0.5698 | Valid loss: 1.0463 | Valid Accu: 0.6462\n",
      "Epoch: 211 | Train loss: 0.8113 | Valid loss: 1.0452 | Valid Accu: 0.6538\n",
      "Epoch: 212 | Train loss: 1.4517 | Valid loss: 1.0391 | Valid Accu: 0.6508\n",
      "Epoch: 212 | Train loss: 0.8765 | Valid loss: 1.0464 | Valid Accu: 0.6440\n",
      "Epoch: 212 | Train loss: 0.6749 | Valid loss: 1.0291 | Valid Accu: 0.6494\n",
      "Epoch: 213 | Train loss: 0.7521 | Valid loss: 1.0868 | Valid Accu: 0.6196\n",
      "Epoch: 213 | Train loss: 0.7623 | Valid loss: 1.0386 | Valid Accu: 0.6462\n",
      "Epoch: 213 | Train loss: 0.8575 | Valid loss: 1.0228 | Valid Accu: 0.6586\n",
      "Epoch: 214 | Train loss: 1.1970 | Valid loss: 1.0595 | Valid Accu: 0.6342\n",
      "Epoch: 214 | Train loss: 0.7222 | Valid loss: 1.0194 | Valid Accu: 0.6476\n",
      "Epoch: 214 | Train loss: 0.9852 | Valid loss: 1.0391 | Valid Accu: 0.6466\n",
      "Epoch: 215 | Train loss: 1.1802 | Valid loss: 1.1142 | Valid Accu: 0.6208\n",
      "Epoch: 215 | Train loss: 1.0373 | Valid loss: 1.0545 | Valid Accu: 0.6500\n",
      "Epoch: 215 | Train loss: 1.4756 | Valid loss: 1.0349 | Valid Accu: 0.6520\n",
      "Epoch: 216 | Train loss: 0.7093 | Valid loss: 1.0356 | Valid Accu: 0.6456\n",
      "Epoch: 216 | Train loss: 1.0266 | Valid loss: 1.0468 | Valid Accu: 0.6408\n",
      "Epoch: 216 | Train loss: 1.0004 | Valid loss: 1.0172 | Valid Accu: 0.6570\n",
      "Epoch: 217 | Train loss: 0.7958 | Valid loss: 1.0167 | Valid Accu: 0.6530\n",
      "Epoch: 217 | Train loss: 1.3446 | Valid loss: 1.0352 | Valid Accu: 0.6436\n",
      "Epoch: 217 | Train loss: 1.2252 | Valid loss: 1.0211 | Valid Accu: 0.6508\n",
      "Epoch: 218 | Train loss: 1.0132 | Valid loss: 1.0225 | Valid Accu: 0.6580\n",
      "Epoch: 218 | Train loss: 0.9207 | Valid loss: 1.0415 | Valid Accu: 0.6416\n",
      "Epoch: 218 | Train loss: 1.2592 | Valid loss: 1.0209 | Valid Accu: 0.6458\n",
      "Epoch: 219 | Train loss: 0.8041 | Valid loss: 1.0613 | Valid Accu: 0.6338\n",
      "Epoch: 219 | Train loss: 1.1034 | Valid loss: 1.0019 | Valid Accu: 0.6520\n",
      "Epoch: 219 | Train loss: 0.8753 | Valid loss: 1.0422 | Valid Accu: 0.6504\n",
      "Epoch: 220 | Train loss: 1.2485 | Valid loss: 1.0459 | Valid Accu: 0.6368\n",
      "Epoch: 220 | Train loss: 0.7745 | Valid loss: 1.0380 | Valid Accu: 0.6466\n",
      "Epoch: 220 | Train loss: 1.0480 | Valid loss: 1.0170 | Valid Accu: 0.6500\n",
      "Epoch: 221 | Train loss: 1.2553 | Valid loss: 1.0607 | Valid Accu: 0.6406\n",
      "Epoch: 221 | Train loss: 0.8498 | Valid loss: 1.0269 | Valid Accu: 0.6514\n",
      "Epoch: 221 | Train loss: 0.9482 | Valid loss: 1.0153 | Valid Accu: 0.6504\n",
      "Epoch: 222 | Train loss: 1.0678 | Valid loss: 1.0241 | Valid Accu: 0.6564\n",
      "Epoch: 222 | Train loss: 0.8644 | Valid loss: 1.0634 | Valid Accu: 0.6400\n",
      "Epoch: 222 | Train loss: 0.8069 | Valid loss: 1.0433 | Valid Accu: 0.6470\n",
      "Epoch: 223 | Train loss: 1.3200 | Valid loss: 1.0324 | Valid Accu: 0.6490\n",
      "Epoch: 223 | Train loss: 0.9331 | Valid loss: 1.0369 | Valid Accu: 0.6430\n",
      "Epoch: 223 | Train loss: 0.6560 | Valid loss: 1.0282 | Valid Accu: 0.6404\n",
      "Epoch: 224 | Train loss: 0.8767 | Valid loss: 1.0560 | Valid Accu: 0.6370\n",
      "Epoch: 224 | Train loss: 0.8082 | Valid loss: 1.0356 | Valid Accu: 0.6490\n",
      "Epoch: 224 | Train loss: 0.9298 | Valid loss: 1.0170 | Valid Accu: 0.6618\n",
      "Epoch: 225 | Train loss: 0.8802 | Valid loss: 1.0412 | Valid Accu: 0.6430\n",
      "Epoch: 225 | Train loss: 0.9512 | Valid loss: 1.0309 | Valid Accu: 0.6448\n",
      "Epoch: 225 | Train loss: 1.2813 | Valid loss: 1.0278 | Valid Accu: 0.6510\n",
      "Epoch: 226 | Train loss: 0.7829 | Valid loss: 1.0327 | Valid Accu: 0.6474\n",
      "Epoch: 226 | Train loss: 0.9337 | Valid loss: 1.0327 | Valid Accu: 0.6458\n",
      "Epoch: 226 | Train loss: 1.0856 | Valid loss: 1.0296 | Valid Accu: 0.6452\n",
      "Epoch: 227 | Train loss: 0.8414 | Valid loss: 1.0641 | Valid Accu: 0.6404\n",
      "Epoch: 227 | Train loss: 1.0360 | Valid loss: 1.0165 | Valid Accu: 0.6538\n",
      "Epoch: 227 | Train loss: 1.0162 | Valid loss: 1.0241 | Valid Accu: 0.6498\n",
      "Epoch: 228 | Train loss: 1.1176 | Valid loss: 1.0149 | Valid Accu: 0.6484\n",
      "Epoch: 228 | Train loss: 0.8784 | Valid loss: 1.0147 | Valid Accu: 0.6570\n",
      "Epoch: 228 | Train loss: 1.0137 | Valid loss: 1.0189 | Valid Accu: 0.6554\n",
      "Epoch: 229 | Train loss: 0.9138 | Valid loss: 1.0630 | Valid Accu: 0.6370\n",
      "Epoch: 229 | Train loss: 1.1672 | Valid loss: 1.0288 | Valid Accu: 0.6508\n",
      "Epoch: 229 | Train loss: 0.7808 | Valid loss: 1.0203 | Valid Accu: 0.6518\n",
      "Epoch: 230 | Train loss: 1.1199 | Valid loss: 1.0441 | Valid Accu: 0.6504\n",
      "Epoch: 230 | Train loss: 1.2621 | Valid loss: 1.0173 | Valid Accu: 0.6494\n",
      "Epoch: 230 | Train loss: 0.6326 | Valid loss: 1.0340 | Valid Accu: 0.6510\n",
      "Epoch: 231 | Train loss: 1.2931 | Valid loss: 1.1088 | Valid Accu: 0.6264\n",
      "Epoch: 231 | Train loss: 0.8180 | Valid loss: 1.0456 | Valid Accu: 0.6394\n",
      "Epoch: 231 | Train loss: 0.9124 | Valid loss: 1.0303 | Valid Accu: 0.6418\n",
      "Epoch: 232 | Train loss: 1.1305 | Valid loss: 1.0113 | Valid Accu: 0.6522\n",
      "Epoch: 232 | Train loss: 1.2784 | Valid loss: 1.0670 | Valid Accu: 0.6360\n",
      "Epoch: 232 | Train loss: 0.8668 | Valid loss: 1.0174 | Valid Accu: 0.6538\n",
      "Epoch: 233 | Train loss: 1.4108 | Valid loss: 1.0253 | Valid Accu: 0.6462\n",
      "Epoch: 233 | Train loss: 0.8372 | Valid loss: 1.0572 | Valid Accu: 0.6360\n",
      "Epoch: 233 | Train loss: 1.2307 | Valid loss: 0.9966 | Valid Accu: 0.6608\n",
      "Epoch: 234 | Train loss: 1.0203 | Valid loss: 1.0201 | Valid Accu: 0.6610\n",
      "Epoch: 234 | Train loss: 1.0839 | Valid loss: 1.0182 | Valid Accu: 0.6572\n",
      "Epoch: 234 | Train loss: 0.8827 | Valid loss: 1.0105 | Valid Accu: 0.6588\n",
      "Epoch: 235 | Train loss: 1.1785 | Valid loss: 1.0213 | Valid Accu: 0.6568\n",
      "Epoch: 235 | Train loss: 1.1827 | Valid loss: 1.0494 | Valid Accu: 0.6380\n",
      "Epoch: 235 | Train loss: 1.5037 | Valid loss: 1.0420 | Valid Accu: 0.6416\n",
      "Epoch: 236 | Train loss: 1.0241 | Valid loss: 1.0371 | Valid Accu: 0.6420\n",
      "Epoch: 236 | Train loss: 0.9612 | Valid loss: 1.0175 | Valid Accu: 0.6580\n",
      "Epoch: 236 | Train loss: 0.9233 | Valid loss: 1.0058 | Valid Accu: 0.6618\n",
      "Epoch: 237 | Train loss: 1.1133 | Valid loss: 1.0393 | Valid Accu: 0.6370\n",
      "Epoch: 237 | Train loss: 0.8285 | Valid loss: 1.0066 | Valid Accu: 0.6634\n",
      "Epoch: 237 | Train loss: 0.6836 | Valid loss: 1.0140 | Valid Accu: 0.6582\n",
      "Epoch: 238 | Train loss: 1.0934 | Valid loss: 1.0237 | Valid Accu: 0.6524\n",
      "Epoch: 238 | Train loss: 1.0719 | Valid loss: 1.0067 | Valid Accu: 0.6554\n",
      "Epoch: 238 | Train loss: 1.3470 | Valid loss: 1.0070 | Valid Accu: 0.6568\n",
      "Epoch: 239 | Train loss: 0.8186 | Valid loss: 1.0259 | Valid Accu: 0.6572\n",
      "Epoch: 239 | Train loss: 1.0889 | Valid loss: 1.0132 | Valid Accu: 0.6558\n",
      "Epoch: 239 | Train loss: 0.9229 | Valid loss: 1.0146 | Valid Accu: 0.6504\n",
      "Epoch: 240 | Train loss: 0.7849 | Valid loss: 1.0621 | Valid Accu: 0.6414\n",
      "Epoch: 240 | Train loss: 0.9848 | Valid loss: 1.0215 | Valid Accu: 0.6524\n",
      "Epoch: 240 | Train loss: 0.9388 | Valid loss: 1.0254 | Valid Accu: 0.6500\n",
      "Epoch: 241 | Train loss: 1.1660 | Valid loss: 1.0200 | Valid Accu: 0.6486\n",
      "Epoch: 241 | Train loss: 0.9220 | Valid loss: 1.0269 | Valid Accu: 0.6500\n",
      "Epoch: 241 | Train loss: 1.3284 | Valid loss: 1.0132 | Valid Accu: 0.6598\n",
      "Epoch: 242 | Train loss: 0.8594 | Valid loss: 1.0370 | Valid Accu: 0.6464\n",
      "Epoch: 242 | Train loss: 0.9968 | Valid loss: 1.0268 | Valid Accu: 0.6472\n",
      "Epoch: 242 | Train loss: 0.8712 | Valid loss: 1.0070 | Valid Accu: 0.6600\n",
      "Epoch: 243 | Train loss: 1.0311 | Valid loss: 1.0376 | Valid Accu: 0.6484\n",
      "Epoch: 243 | Train loss: 1.1390 | Valid loss: 1.0078 | Valid Accu: 0.6594\n",
      "Epoch: 243 | Train loss: 1.0234 | Valid loss: 1.0347 | Valid Accu: 0.6532\n",
      "Epoch: 244 | Train loss: 0.9659 | Valid loss: 1.0260 | Valid Accu: 0.6494\n",
      "Epoch: 244 | Train loss: 0.9030 | Valid loss: 1.0203 | Valid Accu: 0.6548\n",
      "Epoch: 244 | Train loss: 0.6605 | Valid loss: 1.0539 | Valid Accu: 0.6372\n",
      "Epoch: 245 | Train loss: 1.2138 | Valid loss: 1.0053 | Valid Accu: 0.6618\n",
      "Epoch: 245 | Train loss: 0.7007 | Valid loss: 0.9998 | Valid Accu: 0.6610\n",
      "Epoch: 245 | Train loss: 1.0205 | Valid loss: 1.0232 | Valid Accu: 0.6540\n",
      "Epoch: 246 | Train loss: 0.9133 | Valid loss: 1.0321 | Valid Accu: 0.6460\n",
      "Epoch: 246 | Train loss: 0.8750 | Valid loss: 1.0084 | Valid Accu: 0.6574\n",
      "Epoch: 246 | Train loss: 0.8488 | Valid loss: 1.0400 | Valid Accu: 0.6498\n",
      "Epoch: 247 | Train loss: 0.7026 | Valid loss: 1.0669 | Valid Accu: 0.6418\n",
      "Epoch: 247 | Train loss: 0.9108 | Valid loss: 0.9962 | Valid Accu: 0.6636\n",
      "Epoch: 247 | Train loss: 0.9039 | Valid loss: 1.0052 | Valid Accu: 0.6584\n",
      "Epoch: 248 | Train loss: 0.9384 | Valid loss: 1.0243 | Valid Accu: 0.6488\n",
      "Epoch: 248 | Train loss: 1.0366 | Valid loss: 1.0180 | Valid Accu: 0.6526\n",
      "Epoch: 248 | Train loss: 0.7237 | Valid loss: 1.0196 | Valid Accu: 0.6566\n",
      "Epoch: 249 | Train loss: 0.8387 | Valid loss: 1.0632 | Valid Accu: 0.6356\n",
      "Epoch: 249 | Train loss: 0.6432 | Valid loss: 1.0103 | Valid Accu: 0.6566\n",
      "Epoch: 249 | Train loss: 0.9751 | Valid loss: 1.0304 | Valid Accu: 0.6502\n",
      "Epoch: 250 | Train loss: 0.8798 | Valid loss: 1.0262 | Valid Accu: 0.6510\n",
      "Epoch: 250 | Train loss: 0.6895 | Valid loss: 1.0576 | Valid Accu: 0.6446\n",
      "Epoch: 250 | Train loss: 1.0643 | Valid loss: 1.0216 | Valid Accu: 0.6554\n",
      "Epoch: 251 | Train loss: 1.6145 | Valid loss: 1.0115 | Valid Accu: 0.6594\n",
      "Epoch: 251 | Train loss: 1.2866 | Valid loss: 1.0314 | Valid Accu: 0.6448\n",
      "Epoch: 251 | Train loss: 1.0670 | Valid loss: 1.0022 | Valid Accu: 0.6548\n",
      "Epoch: 252 | Train loss: 1.3088 | Valid loss: 1.0324 | Valid Accu: 0.6520\n",
      "Epoch: 252 | Train loss: 1.1023 | Valid loss: 1.0304 | Valid Accu: 0.6506\n",
      "Epoch: 252 | Train loss: 1.1021 | Valid loss: 1.0129 | Valid Accu: 0.6514\n",
      "Epoch: 253 | Train loss: 1.1863 | Valid loss: 1.0097 | Valid Accu: 0.6552\n",
      "Epoch: 253 | Train loss: 1.0843 | Valid loss: 1.0050 | Valid Accu: 0.6628\n",
      "Epoch: 253 | Train loss: 0.8302 | Valid loss: 1.0185 | Valid Accu: 0.6542\n",
      "Epoch: 254 | Train loss: 0.9086 | Valid loss: 1.0155 | Valid Accu: 0.6552\n",
      "Epoch: 254 | Train loss: 1.0046 | Valid loss: 1.0233 | Valid Accu: 0.6564\n",
      "Epoch: 254 | Train loss: 0.6343 | Valid loss: 1.0131 | Valid Accu: 0.6502\n",
      "Epoch: 255 | Train loss: 0.9160 | Valid loss: 1.0354 | Valid Accu: 0.6452\n",
      "Epoch: 255 | Train loss: 0.9928 | Valid loss: 1.0042 | Valid Accu: 0.6562\n",
      "Epoch: 255 | Train loss: 0.8161 | Valid loss: 1.0116 | Valid Accu: 0.6490\n",
      "Epoch: 256 | Train loss: 0.9880 | Valid loss: 1.0346 | Valid Accu: 0.6426\n",
      "Epoch: 256 | Train loss: 0.6591 | Valid loss: 0.9969 | Valid Accu: 0.6654\n",
      "Epoch: 256 | Train loss: 0.7022 | Valid loss: 0.9940 | Valid Accu: 0.6574\n",
      "Epoch: 257 | Train loss: 1.0165 | Valid loss: 1.0146 | Valid Accu: 0.6512\n",
      "Epoch: 257 | Train loss: 0.9435 | Valid loss: 1.0035 | Valid Accu: 0.6572\n",
      "Epoch: 257 | Train loss: 0.9233 | Valid loss: 1.0288 | Valid Accu: 0.6478\n",
      "Epoch: 258 | Train loss: 0.7162 | Valid loss: 1.0780 | Valid Accu: 0.6338\n",
      "Epoch: 258 | Train loss: 0.8144 | Valid loss: 1.0185 | Valid Accu: 0.6558\n",
      "Epoch: 258 | Train loss: 0.9777 | Valid loss: 1.0131 | Valid Accu: 0.6528\n",
      "Epoch: 259 | Train loss: 1.1635 | Valid loss: 1.0249 | Valid Accu: 0.6524\n",
      "Epoch: 259 | Train loss: 0.7393 | Valid loss: 1.0204 | Valid Accu: 0.6470\n",
      "Epoch: 259 | Train loss: 0.7190 | Valid loss: 0.9913 | Valid Accu: 0.6592\n",
      "Epoch: 260 | Train loss: 0.8314 | Valid loss: 1.0127 | Valid Accu: 0.6590\n",
      "Epoch: 260 | Train loss: 0.9196 | Valid loss: 1.0012 | Valid Accu: 0.6542\n",
      "Epoch: 260 | Train loss: 1.0477 | Valid loss: 1.0098 | Valid Accu: 0.6598\n",
      "Epoch: 261 | Train loss: 1.3839 | Valid loss: 1.0173 | Valid Accu: 0.6514\n",
      "Epoch: 261 | Train loss: 1.1086 | Valid loss: 1.0190 | Valid Accu: 0.6476\n",
      "Epoch: 261 | Train loss: 0.7649 | Valid loss: 1.0146 | Valid Accu: 0.6546\n",
      "Epoch: 262 | Train loss: 0.9260 | Valid loss: 1.0285 | Valid Accu: 0.6544\n",
      "Epoch: 262 | Train loss: 1.1705 | Valid loss: 1.0019 | Valid Accu: 0.6634\n",
      "Epoch: 262 | Train loss: 0.9957 | Valid loss: 1.0118 | Valid Accu: 0.6556\n",
      "Epoch: 263 | Train loss: 1.1098 | Valid loss: 1.0340 | Valid Accu: 0.6540\n",
      "Epoch: 263 | Train loss: 0.9947 | Valid loss: 1.0219 | Valid Accu: 0.6502\n",
      "Epoch: 263 | Train loss: 0.5357 | Valid loss: 0.9943 | Valid Accu: 0.6684\n",
      "Epoch: 264 | Train loss: 0.9534 | Valid loss: 1.0034 | Valid Accu: 0.6614\n",
      "Epoch: 264 | Train loss: 1.1722 | Valid loss: 1.0110 | Valid Accu: 0.6654\n",
      "Epoch: 264 | Train loss: 0.8927 | Valid loss: 1.0183 | Valid Accu: 0.6568\n",
      "Epoch: 265 | Train loss: 1.2275 | Valid loss: 1.0143 | Valid Accu: 0.6572\n",
      "Epoch: 265 | Train loss: 0.7488 | Valid loss: 1.0123 | Valid Accu: 0.6532\n",
      "Epoch: 265 | Train loss: 1.0453 | Valid loss: 1.0074 | Valid Accu: 0.6588\n",
      "Epoch: 266 | Train loss: 0.7960 | Valid loss: 1.0242 | Valid Accu: 0.6550\n",
      "Epoch: 266 | Train loss: 0.8332 | Valid loss: 1.0023 | Valid Accu: 0.6572\n",
      "Epoch: 266 | Train loss: 1.4158 | Valid loss: 1.0124 | Valid Accu: 0.6548\n",
      "Epoch: 267 | Train loss: 1.2261 | Valid loss: 1.0511 | Valid Accu: 0.6358\n",
      "Epoch: 267 | Train loss: 0.8867 | Valid loss: 1.0341 | Valid Accu: 0.6478\n",
      "Epoch: 267 | Train loss: 0.8935 | Valid loss: 1.0020 | Valid Accu: 0.6584\n",
      "Epoch: 268 | Train loss: 0.9917 | Valid loss: 1.0171 | Valid Accu: 0.6520\n",
      "Epoch: 268 | Train loss: 0.6810 | Valid loss: 1.0094 | Valid Accu: 0.6558\n",
      "Epoch: 268 | Train loss: 0.8224 | Valid loss: 0.9870 | Valid Accu: 0.6616\n",
      "Epoch: 269 | Train loss: 0.8120 | Valid loss: 1.0443 | Valid Accu: 0.6440\n",
      "Epoch: 269 | Train loss: 1.2264 | Valid loss: 1.0149 | Valid Accu: 0.6584\n",
      "Epoch: 269 | Train loss: 0.8003 | Valid loss: 1.0082 | Valid Accu: 0.6596\n",
      "Epoch: 270 | Train loss: 1.2866 | Valid loss: 0.9992 | Valid Accu: 0.6596\n",
      "Epoch: 270 | Train loss: 0.9039 | Valid loss: 1.0270 | Valid Accu: 0.6460\n",
      "Epoch: 270 | Train loss: 0.9693 | Valid loss: 1.0198 | Valid Accu: 0.6512\n",
      "Epoch: 271 | Train loss: 1.3682 | Valid loss: 1.0322 | Valid Accu: 0.6410\n",
      "Epoch: 271 | Train loss: 1.0591 | Valid loss: 0.9913 | Valid Accu: 0.6594\n",
      "Epoch: 271 | Train loss: 1.0796 | Valid loss: 0.9902 | Valid Accu: 0.6678\n",
      "Epoch: 272 | Train loss: 0.8640 | Valid loss: 1.0075 | Valid Accu: 0.6546\n",
      "Epoch: 272 | Train loss: 1.0716 | Valid loss: 1.0005 | Valid Accu: 0.6600\n",
      "Epoch: 272 | Train loss: 0.9524 | Valid loss: 1.0383 | Valid Accu: 0.6574\n",
      "Epoch: 273 | Train loss: 1.1243 | Valid loss: 1.0303 | Valid Accu: 0.6506\n",
      "Epoch: 273 | Train loss: 0.7455 | Valid loss: 1.0211 | Valid Accu: 0.6574\n",
      "Epoch: 273 | Train loss: 0.9733 | Valid loss: 1.0158 | Valid Accu: 0.6558\n",
      "Epoch: 274 | Train loss: 0.8257 | Valid loss: 1.0201 | Valid Accu: 0.6542\n",
      "Epoch: 274 | Train loss: 0.8350 | Valid loss: 1.0149 | Valid Accu: 0.6532\n",
      "Epoch: 274 | Train loss: 0.7096 | Valid loss: 1.0029 | Valid Accu: 0.6528\n",
      "Epoch: 275 | Train loss: 1.4230 | Valid loss: 1.0264 | Valid Accu: 0.6506\n",
      "Epoch: 275 | Train loss: 0.7391 | Valid loss: 1.0012 | Valid Accu: 0.6592\n",
      "Epoch: 275 | Train loss: 0.6586 | Valid loss: 1.0243 | Valid Accu: 0.6554\n",
      "Epoch: 276 | Train loss: 1.5743 | Valid loss: 1.0319 | Valid Accu: 0.6476\n",
      "Epoch: 276 | Train loss: 1.1231 | Valid loss: 1.0205 | Valid Accu: 0.6540\n",
      "Epoch: 276 | Train loss: 1.3494 | Valid loss: 1.0022 | Valid Accu: 0.6636\n",
      "Epoch: 277 | Train loss: 1.1763 | Valid loss: 0.9978 | Valid Accu: 0.6600\n",
      "Epoch: 277 | Train loss: 0.7908 | Valid loss: 1.0178 | Valid Accu: 0.6530\n",
      "Epoch: 277 | Train loss: 0.6174 | Valid loss: 1.0133 | Valid Accu: 0.6610\n",
      "Epoch: 278 | Train loss: 0.7904 | Valid loss: 1.0188 | Valid Accu: 0.6554\n",
      "Epoch: 278 | Train loss: 0.7680 | Valid loss: 1.0153 | Valid Accu: 0.6590\n",
      "Epoch: 278 | Train loss: 0.8964 | Valid loss: 1.0283 | Valid Accu: 0.6532\n",
      "Epoch: 279 | Train loss: 0.7630 | Valid loss: 0.9888 | Valid Accu: 0.6622\n",
      "Epoch: 279 | Train loss: 0.7950 | Valid loss: 0.9950 | Valid Accu: 0.6610\n",
      "Epoch: 279 | Train loss: 0.9798 | Valid loss: 1.0028 | Valid Accu: 0.6602\n",
      "Epoch: 280 | Train loss: 0.9397 | Valid loss: 0.9989 | Valid Accu: 0.6584\n",
      "Epoch: 280 | Train loss: 0.6796 | Valid loss: 1.0119 | Valid Accu: 0.6596\n",
      "Epoch: 280 | Train loss: 0.9561 | Valid loss: 1.0001 | Valid Accu: 0.6578\n",
      "Epoch: 281 | Train loss: 1.0234 | Valid loss: 1.0236 | Valid Accu: 0.6570\n",
      "Epoch: 281 | Train loss: 1.2698 | Valid loss: 0.9943 | Valid Accu: 0.6616\n",
      "Epoch: 281 | Train loss: 0.8121 | Valid loss: 0.9918 | Valid Accu: 0.6666\n",
      "Epoch: 282 | Train loss: 0.9821 | Valid loss: 1.0210 | Valid Accu: 0.6576\n",
      "Epoch: 282 | Train loss: 1.0908 | Valid loss: 1.0141 | Valid Accu: 0.6590\n",
      "Epoch: 282 | Train loss: 0.8484 | Valid loss: 1.0192 | Valid Accu: 0.6496\n",
      "Epoch: 283 | Train loss: 0.6727 | Valid loss: 1.0545 | Valid Accu: 0.6398\n",
      "Epoch: 283 | Train loss: 0.8812 | Valid loss: 0.9899 | Valid Accu: 0.6604\n",
      "Epoch: 283 | Train loss: 1.2198 | Valid loss: 1.0005 | Valid Accu: 0.6612\n",
      "Epoch: 284 | Train loss: 0.6074 | Valid loss: 1.0215 | Valid Accu: 0.6584\n",
      "Epoch: 284 | Train loss: 0.8274 | Valid loss: 1.0008 | Valid Accu: 0.6534\n",
      "Epoch: 284 | Train loss: 0.9005 | Valid loss: 0.9962 | Valid Accu: 0.6554\n",
      "Epoch: 285 | Train loss: 0.8389 | Valid loss: 1.0012 | Valid Accu: 0.6476\n",
      "Epoch: 285 | Train loss: 1.0027 | Valid loss: 0.9924 | Valid Accu: 0.6644\n",
      "Epoch: 285 | Train loss: 0.8375 | Valid loss: 0.9948 | Valid Accu: 0.6594\n",
      "Epoch: 286 | Train loss: 1.2293 | Valid loss: 1.0134 | Valid Accu: 0.6546\n",
      "Epoch: 286 | Train loss: 0.9549 | Valid loss: 1.0104 | Valid Accu: 0.6542\n",
      "Epoch: 286 | Train loss: 0.6432 | Valid loss: 1.0075 | Valid Accu: 0.6676\n",
      "Epoch: 287 | Train loss: 1.0260 | Valid loss: 1.0549 | Valid Accu: 0.6418\n",
      "Epoch: 287 | Train loss: 1.0560 | Valid loss: 0.9986 | Valid Accu: 0.6508\n",
      "Epoch: 287 | Train loss: 0.9457 | Valid loss: 1.0353 | Valid Accu: 0.6514\n",
      "Epoch: 288 | Train loss: 0.8870 | Valid loss: 1.0254 | Valid Accu: 0.6464\n",
      "Epoch: 288 | Train loss: 0.9862 | Valid loss: 0.9876 | Valid Accu: 0.6674\n",
      "Epoch: 288 | Train loss: 1.0758 | Valid loss: 1.0224 | Valid Accu: 0.6488\n",
      "Epoch: 289 | Train loss: 0.9246 | Valid loss: 1.0110 | Valid Accu: 0.6498\n",
      "Epoch: 289 | Train loss: 1.0789 | Valid loss: 0.9853 | Valid Accu: 0.6662\n",
      "Epoch: 289 | Train loss: 1.0972 | Valid loss: 0.9912 | Valid Accu: 0.6552\n",
      "Epoch: 290 | Train loss: 0.7550 | Valid loss: 1.0121 | Valid Accu: 0.6572\n",
      "Epoch: 290 | Train loss: 0.8758 | Valid loss: 1.0021 | Valid Accu: 0.6614\n",
      "Epoch: 290 | Train loss: 1.2112 | Valid loss: 1.0355 | Valid Accu: 0.6468\n",
      "Epoch: 291 | Train loss: 1.7633 | Valid loss: 1.0079 | Valid Accu: 0.6566\n",
      "Epoch: 291 | Train loss: 0.6156 | Valid loss: 1.0096 | Valid Accu: 0.6496\n",
      "Epoch: 291 | Train loss: 0.9598 | Valid loss: 0.9944 | Valid Accu: 0.6602\n",
      "Epoch: 292 | Train loss: 0.9683 | Valid loss: 0.9969 | Valid Accu: 0.6622\n",
      "Epoch: 292 | Train loss: 0.8381 | Valid loss: 1.0007 | Valid Accu: 0.6604\n",
      "Epoch: 292 | Train loss: 0.7678 | Valid loss: 0.9902 | Valid Accu: 0.6644\n",
      "Epoch: 293 | Train loss: 0.7130 | Valid loss: 0.9912 | Valid Accu: 0.6628\n",
      "Epoch: 293 | Train loss: 1.3209 | Valid loss: 1.0046 | Valid Accu: 0.6584\n",
      "Epoch: 293 | Train loss: 0.7198 | Valid loss: 1.0040 | Valid Accu: 0.6562\n",
      "Epoch: 294 | Train loss: 1.1417 | Valid loss: 1.0018 | Valid Accu: 0.6570\n",
      "Epoch: 294 | Train loss: 1.2698 | Valid loss: 0.9967 | Valid Accu: 0.6574\n",
      "Epoch: 294 | Train loss: 0.8788 | Valid loss: 1.0145 | Valid Accu: 0.6540\n",
      "Epoch: 295 | Train loss: 0.9811 | Valid loss: 1.0010 | Valid Accu: 0.6640\n",
      "Epoch: 295 | Train loss: 0.9347 | Valid loss: 0.9993 | Valid Accu: 0.6604\n",
      "Epoch: 295 | Train loss: 0.8035 | Valid loss: 1.0035 | Valid Accu: 0.6674\n",
      "Epoch: 296 | Train loss: 1.0085 | Valid loss: 0.9917 | Valid Accu: 0.6684\n",
      "Epoch: 296 | Train loss: 0.7090 | Valid loss: 0.9977 | Valid Accu: 0.6586\n",
      "Epoch: 296 | Train loss: 1.2499 | Valid loss: 1.0062 | Valid Accu: 0.6604\n",
      "Epoch: 297 | Train loss: 0.8316 | Valid loss: 1.0296 | Valid Accu: 0.6440\n",
      "Epoch: 297 | Train loss: 0.9154 | Valid loss: 1.0239 | Valid Accu: 0.6492\n",
      "Epoch: 297 | Train loss: 0.7549 | Valid loss: 0.9957 | Valid Accu: 0.6604\n",
      "Epoch: 298 | Train loss: 0.8910 | Valid loss: 1.0053 | Valid Accu: 0.6508\n",
      "Epoch: 298 | Train loss: 1.0409 | Valid loss: 0.9903 | Valid Accu: 0.6646\n",
      "Epoch: 298 | Train loss: 0.9413 | Valid loss: 0.9975 | Valid Accu: 0.6632\n",
      "Epoch: 299 | Train loss: 1.2551 | Valid loss: 1.0112 | Valid Accu: 0.6580\n",
      "Epoch: 299 | Train loss: 0.8388 | Valid loss: 0.9871 | Valid Accu: 0.6626\n",
      "Epoch: 299 | Train loss: 1.2508 | Valid loss: 1.0035 | Valid Accu: 0.6526\n",
      "Epoch: 300 | Train loss: 0.9125 | Valid loss: 1.0076 | Valid Accu: 0.6610\n",
      "Epoch: 300 | Train loss: 0.9273 | Valid loss: 0.9994 | Valid Accu: 0.6660\n",
      "Epoch: 300 | Train loss: 0.9029 | Valid loss: 0.9931 | Valid Accu: 0.6680\n",
      "Epoch: 301 | Train loss: 1.0942 | Valid loss: 0.9809 | Valid Accu: 0.6654\n",
      "Epoch: 301 | Train loss: 0.8540 | Valid loss: 0.9923 | Valid Accu: 0.6654\n",
      "Epoch: 301 | Train loss: 1.0246 | Valid loss: 1.0091 | Valid Accu: 0.6586\n",
      "Epoch: 302 | Train loss: 1.0364 | Valid loss: 0.9878 | Valid Accu: 0.6682\n",
      "Epoch: 302 | Train loss: 0.7707 | Valid loss: 0.9938 | Valid Accu: 0.6664\n",
      "Epoch: 302 | Train loss: 1.1212 | Valid loss: 1.0127 | Valid Accu: 0.6652\n",
      "Epoch: 303 | Train loss: 0.7639 | Valid loss: 0.9881 | Valid Accu: 0.6600\n",
      "Epoch: 303 | Train loss: 1.2015 | Valid loss: 0.9739 | Valid Accu: 0.6730\n",
      "Epoch: 303 | Train loss: 1.1803 | Valid loss: 0.9891 | Valid Accu: 0.6608\n",
      "Epoch: 304 | Train loss: 0.8446 | Valid loss: 0.9993 | Valid Accu: 0.6568\n",
      "Epoch: 304 | Train loss: 0.9387 | Valid loss: 0.9892 | Valid Accu: 0.6648\n",
      "Epoch: 304 | Train loss: 1.3463 | Valid loss: 0.9942 | Valid Accu: 0.6654\n",
      "Epoch: 305 | Train loss: 0.8293 | Valid loss: 1.0079 | Valid Accu: 0.6570\n",
      "Epoch: 305 | Train loss: 0.8047 | Valid loss: 0.9963 | Valid Accu: 0.6528\n",
      "Epoch: 305 | Train loss: 1.1388 | Valid loss: 1.0112 | Valid Accu: 0.6496\n",
      "Epoch: 306 | Train loss: 1.3297 | Valid loss: 1.0081 | Valid Accu: 0.6554\n",
      "Epoch: 306 | Train loss: 0.8557 | Valid loss: 0.9892 | Valid Accu: 0.6628\n",
      "Epoch: 306 | Train loss: 1.3044 | Valid loss: 0.9758 | Valid Accu: 0.6630\n",
      "Epoch: 307 | Train loss: 0.7691 | Valid loss: 1.0058 | Valid Accu: 0.6622\n",
      "Epoch: 307 | Train loss: 0.7765 | Valid loss: 0.9844 | Valid Accu: 0.6598\n",
      "Epoch: 307 | Train loss: 0.9359 | Valid loss: 0.9914 | Valid Accu: 0.6608\n",
      "Epoch: 308 | Train loss: 0.9769 | Valid loss: 1.0309 | Valid Accu: 0.6530\n",
      "Epoch: 308 | Train loss: 1.1645 | Valid loss: 1.0025 | Valid Accu: 0.6576\n",
      "Epoch: 308 | Train loss: 1.1175 | Valid loss: 0.9974 | Valid Accu: 0.6642\n",
      "Epoch: 309 | Train loss: 1.0753 | Valid loss: 0.9994 | Valid Accu: 0.6616\n",
      "Epoch: 309 | Train loss: 1.3016 | Valid loss: 0.9979 | Valid Accu: 0.6502\n",
      "Epoch: 309 | Train loss: 0.7434 | Valid loss: 0.9952 | Valid Accu: 0.6584\n",
      "Epoch: 310 | Train loss: 1.1363 | Valid loss: 0.9910 | Valid Accu: 0.6632\n",
      "Epoch: 310 | Train loss: 0.7679 | Valid loss: 0.9982 | Valid Accu: 0.6588\n",
      "Epoch: 310 | Train loss: 0.9285 | Valid loss: 0.9952 | Valid Accu: 0.6600\n",
      "Epoch: 311 | Train loss: 0.9801 | Valid loss: 1.0048 | Valid Accu: 0.6550\n",
      "Epoch: 311 | Train loss: 0.6225 | Valid loss: 0.9664 | Valid Accu: 0.6726\n",
      "Epoch: 311 | Train loss: 1.0154 | Valid loss: 0.9784 | Valid Accu: 0.6652\n",
      "Epoch: 312 | Train loss: 0.7451 | Valid loss: 1.0117 | Valid Accu: 0.6574\n",
      "Epoch: 312 | Train loss: 0.8468 | Valid loss: 0.9810 | Valid Accu: 0.6638\n",
      "Epoch: 312 | Train loss: 0.7699 | Valid loss: 0.9834 | Valid Accu: 0.6658\n",
      "Epoch: 313 | Train loss: 0.8833 | Valid loss: 1.0068 | Valid Accu: 0.6650\n",
      "Epoch: 313 | Train loss: 1.3386 | Valid loss: 1.0071 | Valid Accu: 0.6634\n",
      "Epoch: 313 | Train loss: 0.8850 | Valid loss: 1.0074 | Valid Accu: 0.6554\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 500\n",
    "best_accu = 0\n",
    "cnt = 0\n",
    "model.train()\n",
    "for epoch in range(num_epoch):\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = lossfunc(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 500 == 0 or i == (len(train_dataset) / 32) - 1 :\n",
    "            # param = next(model.parameters())\n",
    "            # print(param.grad.mean() / param.mean())\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                valid_loss, accu = 0, 0\n",
    "                for j, (x, y) in enumerate(valid_loader):\n",
    "                    x, y = x.to(device), y.to(device)\n",
    "                    pred = model(x)\n",
    "                    valid_loss += lossfunc(pred, y)\n",
    "                    accu += (pred.argmax(-1) == y.squeeze()).sum().item()\n",
    "                # print(accu, valid_loss)\n",
    "                valid_loss /= j\n",
    "                accu /= len(valid_dataset)\n",
    "                del x, y, pred\n",
    "            print(\"Epoch: {} | Train loss: {:.4f} | Valid loss: {:.4f} | Valid Accu: {:.4f}\".format(\n",
    "                epoch, loss.item(), valid_loss.item(), accu\n",
    "            ))\n",
    "            model.train()\n",
    "    # print(\"\\n {:.4f} {:.4f} {} \\n\".format(1.02 * best_accu, accu, cnt))\n",
    "    if accu >= best_accu:\n",
    "        cnt = 0\n",
    "        best_accu = accu\n",
    "        torch.save(model.state_dict(), os.path.join('model', 'cifar',\n",
    "                                                    'model-3C-{}.pt'.format(epoch)))\n",
    "    else:\n",
    "        cnt += 1\n",
    "\n",
    "    if cnt == 50:\n",
    "        # print(\"Early stopped!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6684"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "best_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "epoch - 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = modelClass(num_classes=10).to(device) # torchvision.models.mobilenet_v2(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "modelClass(\n",
       "  (conv0): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv1): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(16, 64, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (fc0): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
       "  (fc2): Linear(in_features=16, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "loaded_model.load_state_dict(torch.load(os.path.join('model', 'cifar', 'model-3C-{}.pt'.format(epoch - 50))))\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accu = 0\n",
    "for _, (x, y) in enumerate(test_loader):\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    pred = loaded_model(x)\n",
    "    test_accu += (pred.argmax(-1) == y).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6909"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "test_accu / len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, loaded_model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "23594"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}